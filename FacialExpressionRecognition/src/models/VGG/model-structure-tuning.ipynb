{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c5f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_height = 48\n",
    "image_width = 48\n",
    "emotions_count = 8\n",
    "emotion_labels = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear', 'contempt']\n",
    "\n",
    "samples = 35393 # 2~35394\n",
    "training_samples = 28317  # 2~28318 (Training)\n",
    "validation_samples = 3541 # 28319~31859 (PublicTest)\n",
    "test_samples = 3535       # 31860~35394 (PrivateTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf15bf17-d948-4fd5-921d-53aa39d26bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, GlobalAveragePooling2D, MaxPool2D, Input, Conv2D, Flatten\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import layers, Sequential,losses, metrics\n",
    "from tensorflow.python.keras import optimizers, callbacks, models\n",
    "from tensorflow.python.keras.optimizer_v2 import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f762c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35393, 48, 48, 1)\n",
      "(35393, 8)\n",
      "(35393, 8)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./dataset/images.npy\"\n",
    "emotion_multi_path = \"./dataset/emotions_multi.npy\"\n",
    "emotion_single_path = \"./dataset/emotions_single.npy\"\n",
    "\n",
    "images = np.load(image_path)\n",
    "emotions_multi = np.load(emotion_multi_path)\n",
    "emotions_single = np.load(emotion_single_path)\n",
    "\n",
    "print(images.shape)\n",
    "print(emotions_multi.shape)\n",
    "print(emotions_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0551b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: (35393, 48, 48, 1)\n",
      "emotions shape: (35393, 8)\n"
     ]
    }
   ],
   "source": [
    "#emotions = emotions_single\n",
    "emotions = emotions_multi\n",
    "\n",
    "images = tf.convert_to_tensor(images)\n",
    "#images = tf.image.grayscale_to_rgb(images)\n",
    "emotions = tf.convert_to_tensor(emotions)\n",
    "print(\"images shape:\", images.shape)\n",
    "print(\"emotions shape:\", emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047e11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import layers\n",
    "# choose one method:\n",
    "images = layers.Rescaling(1./127.5, offset= -1)(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0911f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images shape: (31858, 48, 48, 1)\n",
      "training_emotions shape: (31858, 8)\n",
      "test_images shape: (3535, 48, 48, 1)\n",
      "test_emotions shape: (3535, 8)\n"
     ]
    }
   ],
   "source": [
    "training_size = training_samples + validation_samples\n",
    "test_size = test_samples\n",
    "\n",
    "training_images = images[:training_size]\n",
    "test_images = images[training_size:]\n",
    "training_emotions = emotions[:training_size]\n",
    "test_emotions = emotions[training_size:]\n",
    "\n",
    "print(\"training_images shape:\", training_images.shape)\n",
    "print(\"training_emotions shape:\", training_emotions.shape)\n",
    "print(\"test_images shape:\", test_images.shape)\n",
    "print(\"test_emotions shape:\", test_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8adabf-60e0-48cd-ae8c-04aea07cb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import losses, metrics\n",
    "from tensorflow.python.keras.optimizer_v2 import adam\n",
    "\n",
    "cce = losses.CategoricalCrossentropy()\n",
    "mse = losses.MeanSquaredError()\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "def model_acc(y_true, y_pred):\n",
    "    size = y_true.shape[0]\n",
    "    acc = 0\n",
    "    for i in range(size):\n",
    "        true = y_true[i]\n",
    "        pred = y_pred[i]           \n",
    "        index_max = tf.argmax(pred).numpy()\n",
    "        if true[index_max].numpy()==tf.reduce_max(true).numpy():\n",
    "            acc += 1\n",
    "    return acc/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b48968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 48, 48, 3)\n",
      "feature1 (None, 3)\n",
      "(None, 24, 24, 64)\n",
      "feature2 (None, 64)\n",
      "(None, 12, 12, 128)\n",
      "feature3 (None, 128)\n",
      "(None, 6, 6, 256)\n",
      "feature4 (None, 256)\n",
      "(None, 3, 3, 512)\n",
      "feature5 (None, 512)\n",
      "(None, 512)\n",
      "feature6 (None, 512)\n",
      "combined feature (None, 1475)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 48, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 48, 48, 64)   36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 24, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 24, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 24, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 12, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 12, 12, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 256)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 6, 6, 512)    1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 6, 6, 512)    2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 512)    2359808     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 512)    2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 3)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 256)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 512)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 512)          0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 1475)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "                                                                 global_average_pooling2d_4[0][0] \n",
      "                                                                 global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         6045696     tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         16781312    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            32776       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,264,776\n",
      "Trainable params: 32,264,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "996/996 [==============================] - 72s 67ms/step - loss: 0.0572 - model_acc: 0.3794 - val_loss: 0.0448 - val_model_acc: 0.5470\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 73s 73ms/step - loss: 0.0333 - model_acc: 0.6453 - val_loss: 0.0298 - val_model_acc: 0.6810\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 73s 73ms/step - loss: 0.0241 - model_acc: 0.7297 - val_loss: 0.0228 - val_model_acc: 0.7393\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 69s 70ms/step - loss: 0.0192 - model_acc: 0.7743 - val_loss: 0.0196 - val_model_acc: 0.7585\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0157 - model_acc: 0.8113 - val_loss: 0.0185 - val_model_acc: 0.7803\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0131 - model_acc: 0.8397 - val_loss: 0.0176 - val_model_acc: 0.7887\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0110 - model_acc: 0.8638 - val_loss: 0.0171 - val_model_acc: 0.7922\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0092 - model_acc: 0.8855 - val_loss: 0.0162 - val_model_acc: 0.7953\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 73s 73ms/step - loss: 0.0080 - model_acc: 0.8970 - val_loss: 0.0166 - val_model_acc: 0.8056\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0068 - model_acc: 0.9146 - val_loss: 0.0164 - val_model_acc: 0.7984\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0061 - model_acc: 0.9238 - val_loss: 0.0155 - val_model_acc: 0.8095\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 68s 68ms/step - loss: 0.0054 - model_acc: 0.9313 - val_loss: 0.0152 - val_model_acc: 0.8131\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 71s 72ms/step - loss: 0.0048 - model_acc: 0.9404 - val_loss: 0.0155 - val_model_acc: 0.8063\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0045 - model_acc: 0.9405 - val_loss: 0.0154 - val_model_acc: 0.8157\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0042 - model_acc: 0.9463 - val_loss: 0.0154 - val_model_acc: 0.8165\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0039 - model_acc: 0.9492 - val_loss: 0.0154 - val_model_acc: 0.8111\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 74s 74ms/step - loss: 0.0036 - model_acc: 0.9518 - val_loss: 0.0150 - val_model_acc: 0.8151\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 0.0034 - model_acc: 0.9558 - val_loss: 0.0148 - val_model_acc: 0.8171\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0032 - model_acc: 0.9581 - val_loss: 0.0142 - val_model_acc: 0.8222\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0031 - model_acc: 0.9577 - val_loss: 0.0148 - val_model_acc: 0.8162\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0028 - model_acc: 0.9627 - val_loss: 0.0148 - val_model_acc: 0.8140\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 84s 85ms/step - loss: 0.0028 - model_acc: 0.9632 - val_loss: 0.0147 - val_model_acc: 0.8185\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 587s 590ms/step - loss: 0.0025 - model_acc: 0.9672 - val_loss: 0.0142 - val_model_acc: 0.8218\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 482s 483ms/step - loss: 0.0026 - model_acc: 0.9657 - val_loss: 0.0144 - val_model_acc: 0.8162\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 70s 71ms/step - loss: 0.0024 - model_acc: 0.9664 - val_loss: 0.0144 - val_model_acc: 0.8163\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 68s 68ms/step - loss: 0.0022 - model_acc: 0.9710 - val_loss: 0.0145 - val_model_acc: 0.8241\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 69s 70ms/step - loss: 0.0021 - model_acc: 0.9717 - val_loss: 0.0145 - val_model_acc: 0.8236\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 0.0021 - model_acc: 0.9694 - val_loss: 0.0146 - val_model_acc: 0.8241\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 67s 67ms/step - loss: 0.0020 - model_acc: 0.9720 - val_loss: 0.0141 - val_model_acc: 0.8219\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 0.0019 - model_acc: 0.9752 - val_loss: 0.0143 - val_model_acc: 0.8239\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0015 - model_acc: 0.9796 - val_loss: 0.0137 - val_model_acc: 0.8269\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 67s 67ms/step - loss: 0.0012 - model_acc: 0.9880 - val_loss: 0.0138 - val_model_acc: 0.8275\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 68s 68ms/step - loss: 0.0011 - model_acc: 0.9901 - val_loss: 0.0136 - val_model_acc: 0.8272\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 0.0010 - model_acc: 0.9904 - val_loss: 0.0138 - val_model_acc: 0.8289\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 0.0010 - model_acc: 0.9891 - val_loss: 0.0137 - val_model_acc: 0.8272\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 68s 68ms/step - loss: 9.7654e-04 - model_acc: 0.9890 - val_loss: 0.0137 - val_model_acc: 0.8249\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 9.3429e-04 - model_acc: 0.9892 - val_loss: 0.0137 - val_model_acc: 0.8292\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 67s 67ms/step - loss: 8.9927e-04 - model_acc: 0.9905 - val_loss: 0.0139 - val_model_acc: 0.8311\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 66s 67ms/step - loss: 8.7202e-04 - model_acc: 0.9897 - val_loss: 0.0137 - val_model_acc: 0.8272\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 67s 67ms/step - loss: 8.3579e-04 - model_acc: 0.9907 - val_loss: 0.0139 - val_model_acc: 0.8249\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 7.9788e-04 - model_acc: 0.9906 - val_loss: 0.0137 - val_model_acc: 0.8275\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 7.7263e-04 - model_acc: 0.9907 - val_loss: 0.0137 - val_model_acc: 0.8269\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 7.5265e-04 - model_acc: 0.9919 - val_loss: 0.0139 - val_model_acc: 0.8247\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 7.3008e-04 - model_acc: 0.9910 - val_loss: 0.0138 - val_model_acc: 0.8297\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 7.1540e-04 - model_acc: 0.9913 - val_loss: 0.0137 - val_model_acc: 0.8241\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 6.9342e-04 - model_acc: 0.9926 - val_loss: 0.0137 - val_model_acc: 0.8269\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 66s 67ms/step - loss: 6.7100e-04 - model_acc: 0.9907 - val_loss: 0.0136 - val_model_acc: 0.8252\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 66s 67ms/step - loss: 6.5390e-04 - model_acc: 0.9921 - val_loss: 0.0136 - val_model_acc: 0.8261\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 66s 67ms/step - loss: 6.3576e-04 - model_acc: 0.9916 - val_loss: 0.0137 - val_model_acc: 0.8281\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 6.2902e-04 - model_acc: 0.9919 - val_loss: 0.0137 - val_model_acc: 0.8300\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 6.0865e-04 - model_acc: 0.9917 - val_loss: 0.0136 - val_model_acc: 0.8266\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 5.9049e-04 - model_acc: 0.9929 - val_loss: 0.0137 - val_model_acc: 0.8266\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 67s 67ms/step - loss: 5.8362e-04 - model_acc: 0.9919 - val_loss: 0.0136 - val_model_acc: 0.8292\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 5.6745e-04 - model_acc: 0.9930 - val_loss: 0.0136 - val_model_acc: 0.8264\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 5.6003e-04 - model_acc: 0.9934 - val_loss: 0.0138 - val_model_acc: 0.8283\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 66s 66ms/step - loss: 5.4616e-04 - model_acc: 0.9931 - val_loss: 0.0137 - val_model_acc: 0.8261\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 65s 66ms/step - loss: 5.3248e-04 - model_acc: 0.9924 - val_loss: 0.0136 - val_model_acc: 0.8275\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 66s 66ms/step - loss: 5.2359e-04 - model_acc: 0.9931 - val_loss: 0.0137 - val_model_acc: 0.8292\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 65s 65ms/step - loss: 5.1446e-04 - model_acc: 0.9929 - val_loss: 0.0137 - val_model_acc: 0.8286\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 65s 65ms/step - loss: 5.1619e-04 - model_acc: 0.9929 - val_loss: 0.0138 - val_model_acc: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2219e7690a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications import vgg16, resnet_v2, densenet, efficientnet\n",
    "from tensorflow.python.keras.layers import Dense, GlobalAveragePooling2D, MaxPool2D, Input, Conv2D, Flatten, Concatenate, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import layers, Sequential\n",
    "\n",
    "# VGG13 combined .5dropout\n",
    "input_layer = Input(shape=(48,48,3))\n",
    "print(input_layer.shape)\n",
    "feat1 = GlobalAveragePooling2D()(input_layer)\n",
    "print(\"feature1\", feat1.shape)\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat2 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature2\", feat2.shape)\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat3 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature3\", feat3.shape)\n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "#x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat4 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature4\", feat4.shape)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat5 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature5\", feat5.shape)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "#print(x.shape)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(x.shape)\n",
    "feat6 = x\n",
    "print(\"feature6\", feat6.shape)\n",
    "\n",
    "x = tf.concat([feat1, feat2, feat3, feat4, feat5, feat6], -1)\n",
    "print(\"combined feature\", x.shape)\n",
    "x = Dense(units=4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=4096, activation='relu')(x) \n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(units=8, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=2e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=1e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b8e138",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 48, 48, 3)\n",
      "feature1 (None, 3)\n",
      "(None, 24, 24, 64)\n",
      "feature2 (None, 64)\n",
      "(None, 12, 12, 128)\n",
      "feature3 (None, 128)\n",
      "(None, 6, 6, 256)\n",
      "feature4 (None, 256)\n",
      "(None, 3, 3, 512)\n",
      "feature5 (None, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 512)\n",
      "feature6 (None, 512)\n",
      "combined feature (None, 1475)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 48, 48, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 48, 48, 64)   36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 24, 24, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 24, 24, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 24, 24, 128)  147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 12, 12, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 12, 256)  295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 12, 12, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 6, 6, 256)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 6, 6, 512)    1180160     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 6, 6, 512)    2359808     conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 6, 6, 512)    2359808     conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 512)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 3, 3, 512)    2359808     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 3, 512)    2359808     conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 3, 3, 512)    2359808     conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 2, 2, 512)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 3)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 64)           0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 128)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 256)          0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 512)          0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 512)          0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 1475)         0           global_average_pooling2d_6[0][0] \n",
      "                                                                 global_average_pooling2d_7[0][0] \n",
      "                                                                 global_average_pooling2d_8[0][0] \n",
      "                                                                 global_average_pooling2d_9[0][0] \n",
      "                                                                 global_average_pooling2d_10[0][0]\n",
      "                                                                 global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4096)         6045696     tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4096)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4096)         16781312    dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4096)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            32776       dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 37,574,472\n",
      "Trainable params: 37,574,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 73s 73ms/step - loss: 0.0583 - model_acc: 0.3634 - val_loss: 0.0550 - val_model_acc: 0.4191\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 72s 73ms/step - loss: 0.0368 - model_acc: 0.6155 - val_loss: 0.0304 - val_model_acc: 0.6715\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 74s 74ms/step - loss: 0.0257 - model_acc: 0.7145 - val_loss: 0.0252 - val_model_acc: 0.7182\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 74s 74ms/step - loss: 0.0208 - model_acc: 0.7603 - val_loss: 0.0208 - val_model_acc: 0.7579\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0174 - model_acc: 0.7958 - val_loss: 0.0198 - val_model_acc: 0.7666\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0146 - model_acc: 0.8233 - val_loss: 0.0178 - val_model_acc: 0.7866\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0124 - model_acc: 0.8478 - val_loss: 0.0181 - val_model_acc: 0.7906\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0106 - model_acc: 0.8675 - val_loss: 0.0171 - val_model_acc: 0.7991\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0092 - model_acc: 0.8830 - val_loss: 0.0161 - val_model_acc: 0.8047\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0079 - model_acc: 0.8980 - val_loss: 0.0163 - val_model_acc: 0.8052\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0070 - model_acc: 0.9124 - val_loss: 0.0167 - val_model_acc: 0.8002\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0062 - model_acc: 0.9211 - val_loss: 0.0153 - val_model_acc: 0.8165\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 76s 76ms/step - loss: 0.0055 - model_acc: 0.9299 - val_loss: 0.0152 - val_model_acc: 0.8187\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0051 - model_acc: 0.9360 - val_loss: 0.0157 - val_model_acc: 0.8120\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0046 - model_acc: 0.9405 - val_loss: 0.0148 - val_model_acc: 0.8228\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0043 - model_acc: 0.9420 - val_loss: 0.0147 - val_model_acc: 0.8219\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0039 - model_acc: 0.9483 - val_loss: 0.0145 - val_model_acc: 0.8196\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0037 - model_acc: 0.9525 - val_loss: 0.0152 - val_model_acc: 0.8171\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0034 - model_acc: 0.9552 - val_loss: 0.0146 - val_model_acc: 0.8207\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0032 - model_acc: 0.9591 - val_loss: 0.0147 - val_model_acc: 0.8111\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0032 - model_acc: 0.9572 - val_loss: 0.0149 - val_model_acc: 0.8208\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0030 - model_acc: 0.9598 - val_loss: 0.0143 - val_model_acc: 0.8183\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0028 - model_acc: 0.9633 - val_loss: 0.0143 - val_model_acc: 0.8187\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0026 - model_acc: 0.9646 - val_loss: 0.0146 - val_model_acc: 0.8199\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0025 - model_acc: 0.9655 - val_loss: 0.0142 - val_model_acc: 0.8224\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0023 - model_acc: 0.9675 - val_loss: 0.0145 - val_model_acc: 0.8185\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0023 - model_acc: 0.9688 - val_loss: 0.0141 - val_model_acc: 0.8250\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0022 - model_acc: 0.9690 - val_loss: 0.0143 - val_model_acc: 0.8202\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0021 - model_acc: 0.9730 - val_loss: 0.0142 - val_model_acc: 0.8212\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0020 - model_acc: 0.9723 - val_loss: 0.0141 - val_model_acc: 0.8202\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0016 - model_acc: 0.9805 - val_loss: 0.0134 - val_model_acc: 0.8278\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0012 - model_acc: 0.9896 - val_loss: 0.0134 - val_model_acc: 0.8227\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0011 - model_acc: 0.9916 - val_loss: 0.0134 - val_model_acc: 0.8275\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 0.0010 - model_acc: 0.9909 - val_loss: 0.0135 - val_model_acc: 0.8264\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 9.9372e-04 - model_acc: 0.9908 - val_loss: 0.0135 - val_model_acc: 0.8233\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 9.7162e-04 - model_acc: 0.9907 - val_loss: 0.0135 - val_model_acc: 0.8235\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 9.0662e-04 - model_acc: 0.9921 - val_loss: 0.0135 - val_model_acc: 0.8269\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 8.5687e-04 - model_acc: 0.9917 - val_loss: 0.0136 - val_model_acc: 0.8247\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 8.3074e-04 - model_acc: 0.9919 - val_loss: 0.0135 - val_model_acc: 0.8247\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 7.9006e-04 - model_acc: 0.9925 - val_loss: 0.0137 - val_model_acc: 0.8272\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 7.8091e-04 - model_acc: 0.9917 - val_loss: 0.0135 - val_model_acc: 0.8261\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 7.4782e-04 - model_acc: 0.9931 - val_loss: 0.0136 - val_model_acc: 0.8278\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 7.0897e-04 - model_acc: 0.9932 - val_loss: 0.0134 - val_model_acc: 0.8294\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 6.8994e-04 - model_acc: 0.9926 - val_loss: 0.0136 - val_model_acc: 0.8264\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 6.6829e-04 - model_acc: 0.9936 - val_loss: 0.0135 - val_model_acc: 0.8289\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 6.3858e-04 - model_acc: 0.9940 - val_loss: 0.0136 - val_model_acc: 0.8289\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 6.2588e-04 - model_acc: 0.9930 - val_loss: 0.0135 - val_model_acc: 0.8230\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 6.0470e-04 - model_acc: 0.9941 - val_loss: 0.0135 - val_model_acc: 0.8317\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.8416e-04 - model_acc: 0.9944 - val_loss: 0.0133 - val_model_acc: 0.8306\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.6881e-04 - model_acc: 0.9935 - val_loss: 0.0134 - val_model_acc: 0.8320\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.5340e-04 - model_acc: 0.9937 - val_loss: 0.0136 - val_model_acc: 0.8292\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.4054e-04 - model_acc: 0.9942 - val_loss: 0.0135 - val_model_acc: 0.8264\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.3157e-04 - model_acc: 0.9939 - val_loss: 0.0136 - val_model_acc: 0.8306\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 5.0337e-04 - model_acc: 0.9951 - val_loss: 0.0135 - val_model_acc: 0.8264\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.9640e-04 - model_acc: 0.9944 - val_loss: 0.0133 - val_model_acc: 0.8311\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.9555e-04 - model_acc: 0.9945 - val_loss: 0.0135 - val_model_acc: 0.8314\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.8011e-04 - model_acc: 0.9946 - val_loss: 0.0135 - val_model_acc: 0.8314\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.6740e-04 - model_acc: 0.9951 - val_loss: 0.0135 - val_model_acc: 0.8306\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.5285e-04 - model_acc: 0.9948 - val_loss: 0.0135 - val_model_acc: 0.8292\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 72s 72ms/step - loss: 4.4600e-04 - model_acc: 0.9949 - val_loss: 0.0134 - val_model_acc: 0.8280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224c395b2b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16 .2drop combined features\n",
    "input_layer = Input(shape=(48,48,3))\n",
    "print(input_layer.shape)\n",
    "feat1 = GlobalAveragePooling2D()(input_layer)\n",
    "print(\"feature1\", feat1.shape)\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat2 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature2\", feat2.shape)\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat3 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature3\", feat3.shape)\n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat4 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature4\", feat4.shape)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "feat5 = GlobalAveragePooling2D()(x)\n",
    "print(\"feature5\", feat5.shape)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(x.shape)\n",
    "feat6 = x\n",
    "print(\"feature6\", feat6.shape)\n",
    "\n",
    "x = tf.concat([feat1, feat2, feat3, feat4, feat5, feat6], -1)\n",
    "print(\"combined feature\", x.shape)\n",
    "x = Dense(units=4096, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(units=4096, activation='relu')(x) \n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(units=8, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=2e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=1e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61930bf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 48, 48, 3)\n",
      "(None, 24, 24, 64)\n",
      "(None, 12, 12, 128)\n",
      "(None, 6, 6, 256)\n",
      "(None, 3, 3, 512)\n",
      "(None, 2, 2, 512)\n",
      "(None, 512)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 32776     \n",
      "=================================================================\n",
      "Total params: 33,630,024\n",
      "Trainable params: 33,630,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0543 - model_acc: 0.4292 - val_loss: 0.0399 - val_model_acc: 0.5915\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0333 - model_acc: 0.6428 - val_loss: 0.0304 - val_model_acc: 0.6709\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0271 - model_acc: 0.7042 - val_loss: 0.0271 - val_model_acc: 0.7073\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0225 - model_acc: 0.7456 - val_loss: 0.0246 - val_model_acc: 0.7256\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0189 - model_acc: 0.7828 - val_loss: 0.0214 - val_model_acc: 0.7458\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0158 - model_acc: 0.8125 - val_loss: 0.0200 - val_model_acc: 0.7664\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0137 - model_acc: 0.8353 - val_loss: 0.0182 - val_model_acc: 0.7889\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0115 - model_acc: 0.8602 - val_loss: 0.0175 - val_model_acc: 0.7968\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0098 - model_acc: 0.8791 - val_loss: 0.0176 - val_model_acc: 0.7951\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0087 - model_acc: 0.8926 - val_loss: 0.0169 - val_model_acc: 0.8019\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0075 - model_acc: 0.9071 - val_loss: 0.0169 - val_model_acc: 0.7980\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0067 - model_acc: 0.9171 - val_loss: 0.0171 - val_model_acc: 0.7994\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0057 - model_acc: 0.9279 - val_loss: 0.0167 - val_model_acc: 0.8006\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0054 - model_acc: 0.9313 - val_loss: 0.0171 - val_model_acc: 0.7928\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0053 - model_acc: 0.9335 - val_loss: 0.0177 - val_model_acc: 0.7992\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0047 - model_acc: 0.9421 - val_loss: 0.0156 - val_model_acc: 0.8160\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0042 - model_acc: 0.9460 - val_loss: 0.0161 - val_model_acc: 0.8078\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0040 - model_acc: 0.9490 - val_loss: 0.0159 - val_model_acc: 0.8087\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0036 - model_acc: 0.9546 - val_loss: 0.0153 - val_model_acc: 0.8188\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0037 - model_acc: 0.9519 - val_loss: 0.0181 - val_model_acc: 0.7965\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0036 - model_acc: 0.9532 - val_loss: 0.0157 - val_model_acc: 0.8129\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0028 - model_acc: 0.9642 - val_loss: 0.0152 - val_model_acc: 0.8132\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0026 - model_acc: 0.9667 - val_loss: 0.0152 - val_model_acc: 0.8142\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0026 - model_acc: 0.9660 - val_loss: 0.0152 - val_model_acc: 0.8152\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0027 - model_acc: 0.9640 - val_loss: 0.0160 - val_model_acc: 0.8109\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0027 - model_acc: 0.9646 - val_loss: 0.0154 - val_model_acc: 0.8132\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0022 - model_acc: 0.9719 - val_loss: 0.0155 - val_model_acc: 0.8115\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0021 - model_acc: 0.9734 - val_loss: 0.0149 - val_model_acc: 0.8228\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0024 - model_acc: 0.9686 - val_loss: 0.0157 - val_model_acc: 0.8188\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0021 - model_acc: 0.9716 - val_loss: 0.0154 - val_model_acc: 0.8152\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0015 - model_acc: 0.9837 - val_loss: 0.0147 - val_model_acc: 0.8267\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0012 - model_acc: 0.9921 - val_loss: 0.0147 - val_model_acc: 0.8202\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 0.0010 - model_acc: 0.9925 - val_loss: 0.0146 - val_model_acc: 0.8244\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 9.7084e-04 - model_acc: 0.9928 - val_loss: 0.0146 - val_model_acc: 0.8245\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 9.2127e-04 - model_acc: 0.9915 - val_loss: 0.0146 - val_model_acc: 0.8256\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 8.4856e-04 - model_acc: 0.9935 - val_loss: 0.0145 - val_model_acc: 0.8228\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 7.8512e-04 - model_acc: 0.9934 - val_loss: 0.0147 - val_model_acc: 0.8278\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 7.3493e-04 - model_acc: 0.9933 - val_loss: 0.0147 - val_model_acc: 0.8234\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 6.8525e-04 - model_acc: 0.9938 - val_loss: 0.0146 - val_model_acc: 0.8264\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 6.4406e-04 - model_acc: 0.9942 - val_loss: 0.0146 - val_model_acc: 0.8236\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 6.1519e-04 - model_acc: 0.9944 - val_loss: 0.0147 - val_model_acc: 0.8236\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 5.9157e-04 - model_acc: 0.9947 - val_loss: 0.0146 - val_model_acc: 0.8278\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 5.5908e-04 - model_acc: 0.9948 - val_loss: 0.0147 - val_model_acc: 0.8244\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 5.2996e-04 - model_acc: 0.9950 - val_loss: 0.0147 - val_model_acc: 0.8225\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 5.0204e-04 - model_acc: 0.9951 - val_loss: 0.0146 - val_model_acc: 0.8224\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.8815e-04 - model_acc: 0.9953 - val_loss: 0.0147 - val_model_acc: 0.8236\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.6363e-04 - model_acc: 0.9959 - val_loss: 0.0147 - val_model_acc: 0.8233\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.5697e-04 - model_acc: 0.9959 - val_loss: 0.0145 - val_model_acc: 0.8230\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.3336e-04 - model_acc: 0.9962 - val_loss: 0.0147 - val_model_acc: 0.8267\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.0983e-04 - model_acc: 0.9960 - val_loss: 0.0148 - val_model_acc: 0.8225\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 4.0305e-04 - model_acc: 0.9970 - val_loss: 0.0147 - val_model_acc: 0.8270\n",
      "Epoch 22/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.9349e-04 - model_acc: 0.9957 - val_loss: 0.0146 - val_model_acc: 0.8222\n",
      "Epoch 23/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.7863e-04 - model_acc: 0.9963 - val_loss: 0.0147 - val_model_acc: 0.8259\n",
      "Epoch 24/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.6817e-04 - model_acc: 0.9972 - val_loss: 0.0146 - val_model_acc: 0.8304\n",
      "Epoch 25/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.6779e-04 - model_acc: 0.9968 - val_loss: 0.0144 - val_model_acc: 0.8278\n",
      "Epoch 26/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.4248e-04 - model_acc: 0.9970 - val_loss: 0.0146 - val_model_acc: 0.8256\n",
      "Epoch 27/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.4004e-04 - model_acc: 0.9972 - val_loss: 0.0145 - val_model_acc: 0.8261\n",
      "Epoch 28/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.4439e-04 - model_acc: 0.9974 - val_loss: 0.0146 - val_model_acc: 0.8261\n",
      "Epoch 29/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.1543e-04 - model_acc: 0.9970 - val_loss: 0.0145 - val_model_acc: 0.8287\n",
      "Epoch 30/30\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 3.0162e-04 - model_acc: 0.9981 - val_loss: 0.0147 - val_model_acc: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224ff4c40a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16 no drop/combine\n",
    "input_layer = Input(shape=(48,48,3))\n",
    "print(input_layer.shape)\n",
    "\n",
    "\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "x = Conv2D (filters=64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = Conv2D (filters=256, kernel_size=3, padding='same', activation='relu')(x) \n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D (filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "print(x.shape)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Dense(units=4096, activation='relu')(x)\n",
    "\n",
    "x = Dense(units=4096, activation='relu')(x) \n",
    "\n",
    "output_layer = Dense(units=8, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=2e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))\n",
    "\n",
    "model.compile(optimizer=adam.Adam(learning_rate=1e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2b646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 3.0574e-04 - model_acc: 0.9976 - val_loss: 0.0146 - val_model_acc: 0.8284\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 70s 70ms/step - loss: 2.9840e-04 - model_acc: 0.9976 - val_loss: 0.0147 - val_model_acc: 0.8261\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 70s 70ms/step - loss: 2.9632e-04 - model_acc: 0.9975 - val_loss: 0.0146 - val_model_acc: 0.8239\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 70s 71ms/step - loss: 2.9840e-04 - model_acc: 0.9973 - val_loss: 0.0146 - val_model_acc: 0.8273\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 71s 72ms/step - loss: 2.8331e-04 - model_acc: 0.9976 - val_loss: 0.0145 - val_model_acc: 0.8287\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 71s 71ms/step - loss: 2.7665e-04 - model_acc: 0.9977 - val_loss: 0.0146 - val_model_acc: 0.8295\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 70s 70ms/step - loss: 2.7509e-04 - model_acc: 0.9978 - val_loss: 0.0146 - val_model_acc: 0.8259\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 70s 70ms/step - loss: 2.7946e-04 - model_acc: 0.9974 - val_loss: 0.0145 - val_model_acc: 0.8253\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 69s 69ms/step - loss: 2.7151e-04 - model_acc: 0.9979 - val_loss: 0.0146 - val_model_acc: 0.8256\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 70s 71ms/step - loss: 2.6146e-04 - model_acc: 0.9977 - val_loss: 0.0145 - val_model_acc: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224865f1a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=adam.Adam(learning_rate=1e-4), \n",
    "              loss=mse, \n",
    "              metrics = [model_acc])\n",
    "\n",
    "model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27402318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
