{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import gc\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import scipy.ndimage as ndimage\n",
        "import shapeworks as sw\n",
        "import DeepSSMUtils\n",
        "from DeepSSMUtils import model\n",
        "import nrrd\n",
        "import torchio as tio\n",
        "import monai\n",
        "import nibabel as nib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, positive=False):\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  EPS = np.finfo(np.float).eps\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1675173917015
        },
        "id": "8246ca62",
        "scrolled": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "id": "8246ca62"
    },
    {
      "cell_type": "code",
      "source": [
        "city = 'Beijing_Zang'\n",
        "IMAGE_DIR = f'../dataset/{city}/MRI'\n",
        "MASK_DIR = f'../dataset/{city}/Ventricles3'\n",
        "num_classes = 2\n",
        "TRAIN_SIZE = 10\n",
        "TEST_SIZE = 50\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "output_dir = f'../results/{city}_train10unc_art_part/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1675173917585
        }
      },
      "id": "fe9e2ac9"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_cuda_memory():\n",
        "    t = torch.cuda.get_device_properties(0).total_memory\n",
        "    r = torch.cuda.memory_reserved(0)\n",
        "    a = torch.cuda.memory_allocated(0)\n",
        "    f = r-a  # free inside reserved\n",
        "    print('Total:     {:0.2f} GiB'.format(t / 2**30))\n",
        "    print('Reserved:  {:0.2f} GiB'.format(r / 2**30))\n",
        "    print('Allocated: {:0.2f} GiB'.format(a / 2**30))\n",
        "    print('Free:      {:0.2f} GiB'.format(f / 2**30))\n",
        "\n",
        "show_cuda_memory()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total:     11.17 GiB\nReserved:  0.00 GiB\nAllocated: 0.00 GiB\nFree:      0.00 GiB\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675173918462
        }
      },
      "id": "1b1daaed-0d36-4cca-b9fa-6fa73ecf4a6d"
    },
    {
      "cell_type": "code",
      "source": [
        "deepssm_project = 'DeepSSM_rw1'\n",
        "explained_var = 90\n",
        "\n",
        "deepssm_dir = f'../dataset/All/Ventricles_64_3_cleaned/{deepssm_project}'\n",
        "model_path = f'{deepssm_dir}/DeepSSM{explained_var}.json'\n",
        "state_path = f'{deepssm_dir}/DeepSSM{explained_var}/best_model.torch'\n",
        "\n",
        "deepssm = model.DeepSSMNet(model_path).to(DEVICE)\n",
        "deepssm.load_state_dict(torch.load(state_path))\n",
        "for param in deepssm.parameters():\n",
        "    param.requires_grad = False\n",
        "deepssm.eval()\n",
        "\n",
        "std_PCA = np.load(f'{deepssm_dir}/torch_loaders{explained_var}/std_PCA.npy').reshape(1, -1)\n",
        "std_PCA /= std_PCA.sum()\n",
        "std_PCA = torch.Tensor(std_PCA).to(DEVICE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLP layers: 192 -> 96 -> 48 -> 23\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675173957996
        }
      },
      "id": "042183cb-47c3-4a3f-86a6-34feb6b238c0"
    },
    {
      "cell_type": "code",
      "source": [
        "mask256_dir = f'../dataset/{city}/Ventricles_256_3'\n",
        "\n",
        "centers = np.zeros((TRAIN_SIZE+TEST_SIZE, 3), dtype=int)\n",
        "mus = []\n",
        "for i, path in enumerate(tqdm(sorted(glob(f'{mask256_dir}/*.nrrd'))[:TRAIN_SIZE+TEST_SIZE])):\n",
        "    mask = nrrd.read(path)[0]\n",
        "    centers[i] = ndimage.center_of_mass(mask)\n",
        "    a, b, c = centers[i]\n",
        "    _, _, [mu, _, _, _] = deepssm(\n",
        "        torch.from_numpy(mask[None, None, a-32:a+32, b-32:b+32, c-32:c+32]).to(DEVICE).float()\n",
        "    )\n",
        "    mus.append(mu)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 60/60 [01:49<00:00,  1.82s/it]\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1675174067356
        }
      },
      "id": "4c16e520-205b-4c64-83c3-14c6c80411d3"
    },
    {
      "cell_type": "code",
      "source": [
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.segmentation = monai.networks.nets.UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            channels=(32, 64, 128, 256, 512),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            norm=monai.networks.layers.Norm.BATCH,\n",
        "        )\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.ste = StraightThroughEstimator()\n",
        "\n",
        "    def forward(self, x, i):\n",
        "        mask = self.segmentation(x) # (1, C, 256, 256, 256)\n",
        "        mask = self.softmax(mask) # (1, C, 256, 256, 256)\n",
        "        binary_mask = self.ste(mask - 0.5)\n",
        "\n",
        "        np_mask = binary_mask[0, 1].detach().cpu().numpy()\n",
        "        if np.any(np_mask):\n",
        "            a, b, c = ndimage.center_of_mass(np_mask)\n",
        "            a, b, c = int(a), int(b), int(c)\n",
        "            out = False\n",
        "            for j in [a, b, c]:\n",
        "                if j - 32 < 0 or j + 32 > 256:\n",
        "                    out = True\n",
        "                    break\n",
        "            if out:\n",
        "                a, b, c = centers[i]\n",
        "        else:\n",
        "            a, b, c = centers[i]\n",
        "\n",
        "        # a, b, c = centers[i]\n",
        "\n",
        "        binary_mask = binary_mask[:, 1:2, a-32:a+32, b-32:b+32, c-32:c+32]\n",
        "        _, _, dist_params = deepssm(binary_mask) # (1, PCs)\n",
        "        return mask, dist_params"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1675174067658
        }
      },
      "id": "127d580c"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subjects(image_dir, mask_dir):\n",
        "    subjects = []\n",
        "    for i, image_path in enumerate(tqdm(sorted(glob(f'{image_dir}/*.nii.gz'))[:TRAIN_SIZE+TEST_SIZE], desc='Creating Subjects')):\n",
        "        filename = image_path.split('/')[-1]\n",
        "        mask_path = f'{mask_dir}/{filename}'\n",
        "        subject = tio.Subject(\n",
        "            t1=tio.ScalarImage(\n",
        "                image_path.replace('MRI', 'MRI_arti') if i < TRAIN_SIZE else image_path\n",
        "            ),\n",
        "            label=tio.LabelMap(mask_path),\n",
        "        )\n",
        "        subjects.append(subject)\n",
        "    return subjects\n",
        "\n",
        "all_subjects = get_subjects(IMAGE_DIR, MASK_DIR)\n",
        "subjects = {\n",
        "    'train': all_subjects[:TRAIN_SIZE],\n",
        "    'validation': all_subjects[TRAIN_SIZE:],\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Creating Subjects: 100%|██████████| 60/60 [00:02<00:00, 24.51it/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1675174070389
        },
        "id": "iwKH3_Dd1ehr"
      },
      "id": "iwKH3_Dd1ehr"
    },
    {
      "cell_type": "code",
      "source": [
        "# spatial = tio.OneOf(\n",
        "#     {tio.RandomAffine(degrees=(-3, 3), translation=(-0.1, 0.1)): 1.0},\n",
        "#     p=0.75,\n",
        "# )\n",
        "\n",
        "resample = tio.Compose([\n",
        "    tio.Resample(1),\n",
        "    tio.CropOrPad(256),\n",
        "])\n",
        "\n",
        "signal = tio.Compose([ \n",
        "    tio.RescaleIntensity(percentiles=(0.1, 99.9), out_min_max=(0, 1)),\n",
        "])\n",
        "\n",
        "def get_transform(std):\n",
        "    noise = tio.Compose([ \n",
        "        tio.RandomNoise(mean=0, std=(std, std)),\n",
        "    ])\n",
        "    transform = {\n",
        "        'train': tio.Compose([\n",
        "            # spatial, \n",
        "            resample, \n",
        "            noise,\n",
        "            signal,\n",
        "        ]),\n",
        "        'validation': tio.Compose([\n",
        "            resample, \n",
        "            noise,\n",
        "            signal,\n",
        "        ]),\n",
        "    }\n",
        "    return transform\n",
        "\n",
        "def get_dataloader(transform):\n",
        "    dataloader = dict()\n",
        "    for mode in ['train', 'validation']:\n",
        "        dataloader[mode] = torch.utils.data.DataLoader(\n",
        "            tio.SubjectsDataset(\n",
        "                subjects[mode], \n",
        "                transform=transform[mode]\n",
        "            ),\n",
        "            batch_size=BATCH_SIZE, \n",
        "            num_workers=os.cpu_count(),\n",
        "            shuffle=False,\n",
        "        )\n",
        "    return dataloader"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1675174070592
        },
        "id": "RWe0BZebDKLq"
      },
      "id": "RWe0BZebDKLq"
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loss_dice, loss_mse, metric, losses1, losses2, dscs, std, dataloader, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mean_loss1, mean_loss2, mean_loss_au, mean_loss_eu = 0, 0, 0, 0\n",
        "        for i, subject in enumerate(dataloader['validation']):\n",
        "            image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "            label = subject['label'][tio.DATA].to(DEVICE)\n",
        "\n",
        "            mask, [mu, v, alpha, beta] = model(image, TRAIN_SIZE+i)\n",
        "            one_hot_label = monai.networks.utils.one_hot(\n",
        "                label, num_classes=num_classes, dim=1\n",
        "            ).to(DEVICE)\n",
        "                \n",
        "            loss1 = loss_dice(mask, one_hot_label)\n",
        "            loss2 = torch.abs(mu - mus[TRAIN_SIZE+i]).mean()\n",
        "            loss_au = torch.mean(beta / (alpha - 1))\n",
        "            loss_eu = torch.mean(beta / (v * (alpha - 1)))\n",
        "\n",
        "            # loss2 = torch.sum(std_PCA * pca ** 2)\n",
        "            # loss2 = torch.mean(pca ** 2)\n",
        "            # loss2 = torch.mean((corr_out - corr_outs[TRAIN_SIZE+i]) ** 2)\n",
        "\n",
        "            mean_loss1 += loss1 * image.shape[0]\n",
        "            mean_loss2 += loss2 * image.shape[0]\n",
        "            mean_loss_au += loss_au * image.shape[0]\n",
        "            mean_loss_eu += loss_eu * image.shape[0]\n",
        "\n",
        "            one_hot_pred = monai.networks.utils.one_hot(\n",
        "                torch.argmax(mask, dim=1, keepdim=True), \n",
        "                num_classes=num_classes, \n",
        "                dim=1\n",
        "            ).to(DEVICE)\n",
        "            metric(one_hot_pred, one_hot_label)\n",
        "            \n",
        "            # if i % 10 == 0:\n",
        "            #     if not os.path.exists(f'{output_dir}valimage{i}_label.nrrd'):\n",
        "            #         nrrd.write(f'{output_dir}valimage{i}_label.nrrd', label.detach().cpu().numpy()[0, 0])\n",
        "            #     nrrd.write(f'{output_dir}valimage{i}_prob_epoch{epoch+1}.nrrd', binary_mask.detach().cpu().numpy()[0, 0])\n",
        "\n",
        "            del image, label, mask, one_hot_label, one_hot_pred, loss1, loss2, loss_au, loss_eu, mu, v, alpha, beta\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        mean_loss1 = mean_loss1.item() / TEST_SIZE\n",
        "        mean_loss2 = mean_loss2.item() / TEST_SIZE\n",
        "        mean_loss_au = mean_loss_au.item() / TEST_SIZE\n",
        "        mean_loss_eu = mean_loss_eu.item() / TEST_SIZE\n",
        "        print(f'Validation Loss1: {mean_loss1}')\n",
        "        print(f'Validation Loss2: {mean_loss2}')\n",
        "        print(f'Validation Loss AU: {mean_loss_au}')\n",
        "        print(f'Validation Loss EU: {mean_loss_eu}')\n",
        "\n",
        "        mean_dsc = metric.aggregate().tolist()\n",
        "        metric.reset()\n",
        "        print(f'Validation DSC: {mean_dsc}\\n')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675174070872
        }
      },
      "id": "32b9f1a8-b3e3-4f8a-9425-d55fd64735c0"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_epochs, dataloader, std, weight):\n",
        "    losses1, losses2, dscs = [defaultdict(list) for _ in range(3)]\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4 * 0.99 ** 30)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
        "    loss_dice = monai.losses.DiceLoss(squared_pred=True).to(DEVICE)\n",
        "    loss_mse = torch.nn.MSELoss().to(DEVICE)\n",
        "    metric = monai.metrics.DiceMetric(include_background=False, reduction='mean_batch')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}')\n",
        "        model.train()\n",
        "\n",
        "        mean_loss1, mean_loss2, mean_loss_au, mean_loss_eu = 0, 0, 0, 0\n",
        "        for i, subject in enumerate(dataloader['train']):\n",
        "            \n",
        "            image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "            label = subject['label'][tio.DATA].to(DEVICE)\n",
        "            one_hot_label = monai.networks.utils.one_hot(\n",
        "                label, num_classes=num_classes, dim=1\n",
        "            ).to(DEVICE)\n",
        "        \n",
        "            mask, [mu, v, alpha, beta] = model(image, i)\n",
        "            loss1 = loss_dice(mask, one_hot_label)\n",
        "            loss2 = torch.abs(mu - mus[i]).mean()\n",
        "            loss_au = torch.mean(beta / (alpha - 1))\n",
        "            loss_eu = torch.mean(beta / (v * (alpha - 1)))\n",
        "\n",
        "            # loss2 = loss_mse(pca, pca_scores[i])\n",
        "            # loss2 = torch.sum(std_PCA * pca ** 2)\n",
        "            # loss2 = torch.mean(pca ** 2)\n",
        "            # loss2 = torch.mean((corr_out - corr_outs[i]) ** 2)\n",
        "\n",
        "            loss = loss1 + weight * (loss2 + loss_au + loss_eu)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            mean_loss1 += loss1 * image.shape[0]\n",
        "            mean_loss2 += loss2 * image.shape[0]\n",
        "            mean_loss_au += loss_au * image.shape[0]\n",
        "            mean_loss_eu += loss_eu * image.shape[0]\n",
        "\n",
        "            one_hot_pred = monai.networks.utils.one_hot(\n",
        "                torch.argmax(mask, dim=1, keepdim=True), \n",
        "                num_classes=num_classes, \n",
        "                dim=1\n",
        "            ).to(DEVICE)\n",
        "            metric(one_hot_pred, one_hot_label)\n",
        "\n",
        "            # if i % 10 == 0:\n",
        "            #     if not os.path.exists(f'{output_dir}trainimage{i}_label.nrrd'):\n",
        "            #         nrrd.write(f'{output_dir}trainimage{i}_label.nrrd', label.detach().cpu().numpy()[0, 0])\n",
        "            #     nrrd.write(f'{output_dir}trainimage{i}_prob_epoch{epoch+1}.nrrd', binary_mask.detach().cpu().numpy()[0, 0])\n",
        "\n",
        "            del image, label, mask, one_hot_label, one_hot_pred, loss, loss1, loss2, loss_au, loss_eu, mu, v, alpha, beta\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        mean_loss1 = mean_loss1.item() / TRAIN_SIZE\n",
        "        mean_loss2 = mean_loss2.item() / TRAIN_SIZE\n",
        "        mean_loss_au = mean_loss_au.item() / TRAIN_SIZE\n",
        "        mean_loss_eu = mean_loss_eu.item() / TRAIN_SIZE\n",
        "        print(f'Train Loss1: {mean_loss1}')\n",
        "        print(f'Train Loss2: {mean_loss2}')\n",
        "        print(f'Train Loss AU: {mean_loss_au}')\n",
        "        print(f'Train Loss EU: {mean_loss_eu}')\n",
        "\n",
        "        mean_dsc = metric.aggregate().tolist()\n",
        "        metric.reset()\n",
        "        print(f'Train DSC: {mean_dsc}')\n",
        "\n",
        "        validate(model, loss_dice, loss_mse, metric, losses1, losses2, dscs, std, dataloader, epoch)\n",
        "\n",
        "        # if (epoch+1) % 10 == 0:\n",
        "        #     torch.save(model.state_dict(), f'{output_dir}model_epoch{epoch+1}.pth')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675174071120
        }
      },
      "id": "bf064a15-780b-401a-9689-162ee97f7899"
    },
    {
      "cell_type": "code",
      "source": [
        "std = 0\n",
        "transform = get_transform(std=std)\n",
        "dataloader = get_dataloader(transform)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675174071390
        }
      },
      "id": "3db80ece-41da-45b6-9d6d-bc6f42dd6a0b"
    },
    {
      "cell_type": "code",
      "source": [
        "for weight in [0.3, 0.5]:\n",
        "    print(f'weight: {weight}')\n",
        "    model = Model().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(f'{output_dir}model_epoch30.pth'))\n",
        "    train(model, n_epochs=30, dataloader=dataloader, std=std, weight=weight)\n",
        "\n",
        "    # torch.save(model.state_dict(), f'{output_dir}/UNet_std1000.pth')\n",
        "\n",
        "    del model#, transform, dataloader, losses1, losses2, dscs\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "weight: 0.3\nEpoch 1/30\nTrain Loss1: 0.18345942497253417\nTrain Loss2: 0.1873113751411438\nTrain Loss AU: 0.3035589218139648\nTrain Loss EU: 0.38634819984436036\nTrain DSC: [0.6925975680351257]\nValidation Loss1: 0.20671138763427735\nValidation Loss2: 0.228212890625\nValidation Loss AU: 0.33244895935058594\nValidation Loss EU: 0.40496665954589844\nValidation DSC: [0.6427181959152222]\n\nEpoch 2/30\nTrain Loss1: 0.1561685562133789\nTrain Loss2: 0.15501117706298828\nTrain Loss AU: 0.28419544696807864\nTrain Loss EU: 0.3742222309112549\nTrain DSC: [0.7347933650016785]\nValidation Loss1: 0.21047082901000977\nValidation Loss2: 0.2594340515136719\nValidation Loss AU: 0.34664169311523435\nValidation Loss EU: 0.41710739135742186\nValidation DSC: [0.5866115689277649]\n\nEpoch 3/30\nTrain Loss1: 0.14797120094299315\nTrain Loss2: 0.1644556403160095\nTrain Loss AU: 0.28671631813049314\nTrain Loss EU: 0.3681331634521484\nTrain DSC: [0.7377884387969971]\nValidation Loss1: 0.2704115295410156\nValidation Loss2: 0.3139496803283691\nValidation Loss AU: 0.3876429748535156\nValidation Loss EU: 0.4569210433959961\nValidation DSC: [0.4661770164966583]\n\nEpoch 4/30\nTrain Loss1: 0.13866014480590821\nTrain Loss2: 0.14899808168411255\nTrain Loss AU: 0.29471120834350584\nTrain Loss EU: 0.37720456123352053\nTrain DSC: [0.750403106212616]\nValidation Loss1: 0.1651350212097168\nValidation Loss2: 0.2074275016784668\nValidation Loss AU: 0.31629640579223633\nValidation Loss EU: 0.39460636138916017\nValidation DSC: [0.6764566898345947]\n\nEpoch 5/30\nTrain Loss1: 0.13933149576187134\nTrain Loss2: 0.1443837285041809\nTrain Loss AU: 0.2886418342590332\nTrain Loss EU: 0.373192286491394\nTrain DSC: [0.7347702980041504]\nValidation Loss1: 0.18762197494506835\nValidation Loss2: 0.24757007598876954\nValidation Loss AU: 0.3297943878173828\nValidation Loss EU: 0.402372932434082\nValidation DSC: [0.624433696269989]\n\nEpoch 6/30\nTrain Loss1: 0.13581674098968505\nTrain Loss2: 0.17974364757537842\nTrain Loss AU: 0.28317382335662844\nTrain Loss EU: 0.37323248386383057\nTrain DSC: [0.7338694930076599]\nValidation Loss1: 0.22721582412719726\nValidation Loss2: 0.28795221328735354\nValidation Loss AU: 0.35390186309814453\nValidation Loss EU: 0.4270142364501953\nValidation DSC: [0.5274137258529663]\n\nEpoch 7/30\nTrain Loss1: 0.13511145114898682\nTrain Loss2: 0.1604848861694336\nTrain Loss AU: 0.2854607343673706\nTrain Loss EU: 0.3842183589935303\nTrain DSC: [0.7333792448043823]\nValidation Loss1: 0.19195892333984374\nValidation Loss2: 0.2386772918701172\nValidation Loss AU: 0.35339763641357425\nValidation Loss EU: 0.4233401107788086\nValidation DSC: [0.603924036026001]\n\nEpoch 8/30\nTrain Loss1: 0.14296290874481202\nTrain Loss2: 0.1837999105453491\nTrain Loss AU: 0.28386726379394533\nTrain Loss EU: 0.37068891525268555\nTrain DSC: [0.7080351114273071]\nValidation Loss1: 0.15208110809326172\nValidation Loss2: 0.20654935836791993\nValidation Loss AU: 0.3201536560058594\nValidation Loss EU: 0.401147346496582\nValidation DSC: [0.6806663274765015]\n\nEpoch 9/30\nTrain Loss1: 0.12354686260223388\nTrain Loss2: 0.14174063205718995\nTrain Loss AU: 0.27815248966217043\nTrain Loss EU: 0.3713870048522949\nTrain DSC: [0.7544076442718506]\nValidation Loss1: 0.16796606063842773\nValidation Loss2: 0.23170677185058594\nValidation Loss AU: 0.31409095764160155\nValidation Loss EU: 0.3923759841918945\nValidation DSC: [0.6588384509086609]\n\nEpoch 10/30\nTrain Loss1: 0.11201217174530029\nTrain Loss2: 0.12844828367233277\nTrain Loss AU: 0.282444429397583\nTrain Loss EU: 0.36986777782440183\nTrain DSC: [0.7726880311965942]\nValidation Loss1: 0.1996573257446289\nValidation Loss2: 0.2650651550292969\nValidation Loss AU: 0.33618839263916017\nValidation Loss EU: 0.4079734420776367\nValidation DSC: [0.5926638841629028]\n\nEpoch 11/30\nTrain Loss1: 0.10962804555892944\nTrain Loss2: 0.13631417751312255\nTrain Loss AU: 0.26454997062683105\nTrain Loss EU: 0.36861069202423097\nTrain DSC: [0.7725197076797485]\nValidation Loss1: 0.19592084884643554\nValidation Loss2: 0.26288909912109376\nValidation Loss AU: 0.34493480682373046\nValidation Loss EU: 0.4172907638549805\nValidation DSC: [0.5801129937171936]\n\nEpoch 12/30\nTrain Loss1: 0.10385854244232177\nTrain Loss2: 0.12127923965454102\nTrain Loss AU: 0.28125045299530027\nTrain Loss EU: 0.36812314987182615\nTrain DSC: [0.7870358228683472]\nValidation Loss1: 0.1949087905883789\nValidation Loss2: 0.2705115509033203\nValidation Loss AU: 0.33507511138916013\nValidation Loss EU: 0.4112176513671875\nValidation DSC: [0.5837081074714661]\n\nEpoch 13/30\nTrain Loss1: 0.09850503206253051\nTrain Loss2: 0.10616519451141357\nTrain Loss AU: 0.2719618320465088\nTrain Loss EU: 0.3670603036880493\nTrain DSC: [0.7951017618179321]\nValidation Loss1: 0.1561812400817871\nValidation Loss2: 0.22855758666992188\nValidation Loss AU: 0.31743764877319336\nValidation Loss EU: 0.39490684509277346\nValidation DSC: [0.6644877791404724]\n\nEpoch 14/30\nTrain Loss1: 0.09995808005332947\nTrain Loss2: 0.11095656156539917\nTrain Loss AU: 0.2756004333496094\nTrain Loss EU: 0.37084593772888186\nTrain DSC: [0.7900846600532532]\nValidation Loss1: 0.1522548484802246\nValidation Loss2: 0.22408449172973632\nValidation Loss AU: 0.3181044578552246\nValidation Loss EU: 0.3928696823120117\nValidation DSC: [0.6715800762176514]\n\nEpoch 15/30\nTrain Loss1: 0.09621255397796631\nTrain Loss2: 0.12983666658401488\nTrain Loss AU: 0.27159581184387205\nTrain Loss EU: 0.3669348001480103\nTrain DSC: [0.7960652112960815]\nValidation Loss1: 0.15959759712219238\nValidation Loss2: 0.22011999130249024\nValidation Loss AU: 0.3256968307495117\nValidation Loss EU: 0.4004994583129883\nValidation DSC: [0.6537777185440063]\n\nEpoch 16/30\nTrain Loss1: 0.09680789709091187\nTrain Loss2: 0.12174797058105469\nTrain Loss AU: 0.2725989818572998\nTrain Loss EU: 0.3624293327331543\nTrain DSC: [0.7936900854110718]\nValidation Loss1: 0.13976977348327638\nValidation Loss2: 0.20417564392089843\nValidation Loss AU: 0.3185932350158691\nValidation Loss EU: 0.39587905883789065\nValidation DSC: [0.6957000494003296]\n\nEpoch 17/30\nTrain Loss1: 0.08837400674819947\nTrain Loss2: 0.09181538224220276\nTrain Loss AU: 0.2778442144393921\nTrain Loss EU: 0.36453568935394287\nTrain DSC: [0.811296820640564]\nValidation Loss1: 0.14598758697509764\nValidation Loss2: 0.21548109054565429\nValidation Loss AU: 0.3138541603088379\nValidation Loss EU: 0.394586181640625\nValidation DSC: [0.6804772019386292]\n\nEpoch 18/30\nTrain Loss1: 0.09403152465820312\nTrain Loss2: 0.1042018175125122\nTrain Loss AU: 0.2649387836456299\nTrain Loss EU: 0.3609903335571289\nTrain DSC: [0.7986217141151428]\nValidation Loss1: 0.21821521759033202\nValidation Loss2: 0.3016622543334961\nValidation Loss AU: 0.3639784240722656\nValidation Loss EU: 0.4406332015991211\nValidation DSC: [0.5200536251068115]\n\nEpoch 19/30\nTrain Loss1: 0.08963013887405395\nTrain Loss2: 0.1382446050643921\nTrain Loss AU: 0.26975600719451903\nTrain Loss EU: 0.3704380512237549\nTrain DSC: [0.8063600659370422]\nValidation Loss1: 0.1408083438873291\nValidation Loss2: 0.20253021240234376\nValidation Loss AU: 0.3181865501403809\nValidation Loss EU: 0.4035569000244141\nValidation DSC: [0.6918504238128662]\n\nEpoch 20/30\nTrain Loss1: 0.08873131275177001\nTrain Loss2: 0.11697789430618286\nTrain Loss AU: 0.2729960441589355\nTrain Loss EU: 0.3623572826385498\nTrain DSC: [0.8065269589424133]\nValidation Loss1: 0.1434480094909668\nValidation Loss2: 0.20373418807983398\nValidation Loss AU: 0.3310006332397461\nValidation Loss EU: 0.4091130065917969\nValidation DSC: [0.6845743060112]\n\nEpoch 21/30\nTrain Loss1: 0.07904835939407348\nTrain Loss2: 0.07985509037971497\nTrain Loss AU: 0.2745157241821289\nTrain Loss EU: 0.3619060516357422\nTrain DSC: [0.8306732177734375]\nValidation Loss1: 0.1861422348022461\nValidation Loss2: 0.26579919815063474\nValidation Loss AU: 0.33738002777099607\nValidation Loss EU: 0.4103894424438477\nValidation DSC: [0.5929864645004272]\n\nEpoch 22/30\nTrain Loss1: 0.07877740859985352\nTrain Loss2: 0.0897039532661438\nTrain Loss AU: 0.26963090896606445\nTrain Loss EU: 0.36789238452911377\nTrain DSC: [0.8288820385932922]\nValidation Loss1: 0.21406906127929687\nValidation Loss2: 0.29505794525146484\nValidation Loss AU: 0.3610783767700195\nValidation Loss EU: 0.43850685119628907\nValidation DSC: [0.5304881930351257]\n\nEpoch 23/30\nTrain Loss1: 0.07621852159500123\nTrain Loss2: 0.10007195472717285\nTrain Loss AU: 0.26545488834381104\nTrain Loss EU: 0.35932087898254395\nTrain DSC: [0.8338291049003601]\nValidation Loss1: 0.1350029468536377\nValidation Loss2: 0.21377885818481446\nValidation Loss AU: 0.3197706413269043\nValidation Loss EU: 0.39907257080078123\nValidation DSC: [0.6992383003234863]\n\nEpoch 24/30\nTrain Loss1: 0.07771007418632507\nTrain Loss2: 0.09665433168411255\nTrain Loss AU: 0.2787581443786621\nTrain Loss EU: 0.36785919666290284\nTrain DSC: [0.828194260597229]\nValidation Loss1: 0.12644454956054688\nValidation Loss2: 0.19560758590698243\nValidation Loss AU: 0.3155170822143555\nValidation Loss EU: 0.3976424789428711\nValidation DSC: [0.720763087272644]\n\nEpoch 25/30\nTrain Loss1: 0.08058861494064332\nTrain Loss2: 0.10042541027069092\nTrain Loss AU: 0.2755217313766479\nTrain Loss EU: 0.36490142345428467\nTrain DSC: [0.8240469694137573]\nValidation Loss1: 0.1275272274017334\nValidation Loss2: 0.19881248474121094\nValidation Loss AU: 0.31117589950561525\nValidation Loss EU: 0.3955435562133789\nValidation DSC: [0.716050922870636]\n\nEpoch 26/30\nTrain Loss1: 0.07384238243103028\nTrain Loss2: 0.07888104915618896\nTrain Loss AU: 0.27100656032562254\nTrain Loss EU: 0.36108582019805907\nTrain DSC: [0.8362539410591125]\nValidation Loss1: 0.22273920059204103\nValidation Loss2: 0.30592382431030274\nValidation Loss AU: 0.3665110015869141\nValidation Loss EU: 0.4432662582397461\nValidation DSC: [0.5113660097122192]\n\nEpoch 27/30\nTrain Loss1: 0.07422062158584594\nTrain Loss2: 0.09478768706321716\nTrain Loss AU: 0.2740196228027344\nTrain Loss EU: 0.3679059505462646\nTrain DSC: [0.8364903330802917]\nValidation Loss1: 0.140602445602417\nValidation Loss2: 0.21546953201293945\nValidation Loss AU: 0.3255732345581055\nValidation Loss EU: 0.40418712615966795\nValidation DSC: [0.6851454377174377]\n\nEpoch 28/30\nTrain Loss1: 0.06862086057662964\nTrain Loss2: 0.0807848334312439\nTrain Loss AU: 0.2714277744293213\nTrain Loss EU: 0.3651134967803955\nTrain DSC: [0.8495537042617798]\nValidation Loss1: 0.12774630546569823\nValidation Loss2: 0.1979120635986328\nValidation Loss AU: 0.3156756973266602\nValidation Loss EU: 0.39406757354736327\nValidation DSC: [0.7132192254066467]\n\nEpoch 29/30\nTrain Loss1: 0.0659906268119812\nTrain Loss2: 0.07861239910125732\nTrain Loss AU: 0.2739673137664795\nTrain Loss EU: 0.36385653018951414\nTrain DSC: [0.8555313944816589]\nValidation Loss1: 0.13459060668945313\nValidation Loss2: 0.2156725311279297\nValidation Loss AU: 0.3108920860290527\nValidation Loss EU: 0.3963193893432617\nValidation DSC: [0.695417046546936]\n\nEpoch 30/30\nTrain Loss1: 0.06295489072799683\nTrain Loss2: 0.09137529134750366\nTrain Loss AU: 0.25402700901031494\nTrain Loss EU: 0.37009596824645996\nTrain DSC: [0.8610900640487671]\nValidation Loss1: 0.1744095802307129\nValidation Loss2: 0.2569640350341797\nValidation Loss AU: 0.33862312316894533\nValidation Loss EU: 0.41479709625244143\nValidation DSC: [0.6119997501373291]\n\nweight: 0.5\nEpoch 1/30\nTrain Loss1: 0.19246901273727418\nTrain Loss2: 0.21105437278747557\nTrain Loss AU: 0.32394838333129883\nTrain Loss EU: 0.4015077590942383\nTrain DSC: [0.6678833365440369]\nValidation Loss1: 0.2908260726928711\nValidation Loss2: 0.3053827667236328\nValidation Loss AU: 0.3853308868408203\nValidation Loss EU: 0.45203361511230467\nValidation DSC: [0.4666689932346344]\n\nEpoch 2/30\nTrain Loss1: 0.17552714347839354\nTrain Loss2: 0.1683841586112976\nTrain Loss AU: 0.28929111957550047\nTrain Loss EU: 0.37265405654907224\nTrain DSC: [0.6946691274642944]\nValidation Loss1: 0.20509639739990235\nValidation Loss2: 0.2543410110473633\nValidation Loss AU: 0.34234004974365234\nValidation Loss EU: 0.41143089294433594\nValidation DSC: [0.5968692302703857]\n\nEpoch 3/30\nTrain Loss1: 0.1641150951385498\nTrain Loss2: 0.162492835521698\nTrain Loss AU: 0.2898286819458008\nTrain Loss EU: 0.37233695983886717\nTrain DSC: [0.7057687640190125]\nValidation Loss1: 0.23742416381835937\nValidation Loss2: 0.2917384147644043\nValidation Loss AU: 0.36323898315429687\nValidation Loss EU: 0.4345111465454102\nValidation DSC: [0.5371137857437134]\n\nEpoch 4/30\nTrain Loss1: 0.15588977336883544\nTrain Loss2: 0.159242844581604\nTrain Loss AU: 0.28498818874359133\nTrain Loss EU: 0.3687602519989014\nTrain DSC: [0.7082357406616211]\nValidation Loss1: 0.18408586502075194\nValidation Loss2: 0.20908502578735352\nValidation Loss AU: 0.31383190155029295\nValidation Loss EU: 0.3937926483154297\nValidation DSC: [0.6497246026992798]\n\nEpoch 5/30\nTrain Loss1: 0.14562053680419923\nTrain Loss2: 0.14816206693649292\nTrain Loss AU: 0.2726911544799805\nTrain Loss EU: 0.35884501934051516\nTrain DSC: [0.7245573997497559]\nValidation Loss1: 0.18238054275512694\nValidation Loss2: 0.23262496948242187\nValidation Loss AU: 0.32720279693603516\nValidation Loss EU: 0.3978124618530273\nValidation DSC: [0.644614040851593]\n\nEpoch 6/30\nTrain Loss1: 0.1384279727935791\nTrain Loss2: 0.12586530447006225\nTrain Loss AU: 0.2700234889984131\nTrain Loss EU: 0.36845667362213136\nTrain DSC: [0.7323285341262817]\nValidation Loss1: 0.1861386489868164\nValidation Loss2: 0.2356913948059082\nValidation Loss AU: 0.3239473342895508\nValidation Loss EU: 0.39817764282226564\nValidation DSC: [0.6233879327774048]\n\nEpoch 7/30\nTrain Loss1: 0.15047409534454345\nTrain Loss2: 0.1730138063430786\nTrain Loss AU: 0.28426992893218994\nTrain Loss EU: 0.36439197063446044\nTrain DSC: [0.6986592411994934]\nValidation Loss1: 0.1759622001647949\nValidation Loss2: 0.23015308380126953\nValidation Loss AU: 0.31236557006835936\nValidation Loss EU: 0.39199142456054686\nValidation DSC: [0.6440746188163757]\n\nEpoch 8/30\nTrain Loss1: 0.13652726411819457\nTrain Loss2: 0.15107544660568237\nTrain Loss AU: 0.2759177446365356\nTrain Loss EU: 0.3647195339202881\nTrain DSC: [0.7297894954681396]\nValidation Loss1: 0.16819305419921876\nValidation Loss2: 0.21874645233154297\nValidation Loss AU: 0.3178765869140625\nValidation Loss EU: 0.39846981048583985\nValidation DSC: [0.6586296558380127]\n\nEpoch 9/30\nTrain Loss1: 0.13226277828216554\nTrain Loss2: 0.12608975172042847\nTrain Loss AU: 0.2747304916381836\nTrain Loss EU: 0.36778690814971926\nTrain DSC: [0.7325057983398438]\nValidation Loss1: 0.17750864028930663\nValidation Loss2: 0.250418701171875\nValidation Loss AU: 0.32860740661621096\nValidation Loss EU: 0.4006509780883789\nValidation DSC: [0.6333680152893066]\n\nEpoch 10/30\nTrain Loss1: 0.1260775089263916\nTrain Loss2: 0.12996976375579833\nTrain Loss AU: 0.26222307682037355\nTrain Loss EU: 0.3699833869934082\nTrain DSC: [0.7387529611587524]\nValidation Loss1: 0.20628522872924804\nValidation Loss2: 0.2746713066101074\nValidation Loss AU: 0.34407482147216795\nValidation Loss EU: 0.415348014831543\nValidation DSC: [0.5658740401268005]\n\nEpoch 11/30\nTrain Loss1: 0.12158159017562867\nTrain Loss2: 0.1203505516052246\nTrain Loss AU: 0.2803181171417236\nTrain Loss EU: 0.36368398666381835\nTrain DSC: [0.7509596943855286]\nValidation Loss1: 0.15845776557922364\nValidation Loss2: 0.23015483856201172\nValidation Loss AU: 0.31624515533447267\nValidation Loss EU: 0.3925079345703125\nValidation DSC: [0.6609290838241577]\n\nEpoch 12/30\nTrain Loss1: 0.11347875595092774\nTrain Loss2: 0.10206971168518067\nTrain Loss AU: 0.27480478286743165\nTrain Loss EU: 0.3653433084487915\nTrain DSC: [0.7642248272895813]\nValidation Loss1: 0.27716182708740233\nValidation Loss2: 0.3470059585571289\nValidation Loss AU: 0.40948719024658203\nValidation Loss EU: 0.4838637542724609\nValidation DSC: [0.4086742401123047]\n\nEpoch 13/30\nTrain Loss1: 0.11638826131820679\nTrain Loss2: 0.11960245370864868\nTrain Loss AU: 0.2807031154632568\nTrain Loss EU: 0.37131476402282715\nTrain DSC: [0.7558954358100891]\nValidation Loss1: 0.2176224708557129\nValidation Loss2: 0.2927635955810547\nValidation Loss AU: 0.3506548309326172\nValidation Loss EU: 0.4235200881958008\nValidation DSC: [0.5314772129058838]\n\nEpoch 14/30\nTrain Loss1: 0.12288057804107666\nTrain Loss2: 0.1149522066116333\nTrain Loss AU: 0.27152655124664304\nTrain Loss EU: 0.37179453372955323\nTrain DSC: [0.7395302057266235]\nValidation Loss1: 0.18921724319458008\nValidation Loss2: 0.24010200500488282\nValidation Loss AU: 0.36306915283203123\nValidation Loss EU: 0.4332596206665039\nValidation DSC: [0.5934314131736755]\n\nEpoch 15/30\nTrain Loss1: 0.11448090076446533\nTrain Loss2: 0.128872811794281\nTrain Loss AU: 0.2693084955215454\nTrain Loss EU: 0.35935020446777344\nTrain DSC: [0.7588832974433899]\nValidation Loss1: 0.16587287902832032\nValidation Loss2: 0.2237209129333496\nValidation Loss AU: 0.31768898010253904\nValidation Loss EU: 0.3941060638427734\nValidation DSC: [0.6527855396270752]\n\nEpoch 16/30\nTrain Loss1: 0.10594873428344727\nTrain Loss2: 0.11206909418106079\nTrain Loss AU: 0.2664264917373657\nTrain Loss EU: 0.35900943279266356\nTrain DSC: [0.7735331058502197]\nValidation Loss1: 0.14582865715026855\nValidation Loss2: 0.2107207679748535\nValidation Loss AU: 0.31324859619140627\nValidation Loss EU: 0.38948806762695315\nValidation DSC: [0.6852705478668213]\n\nEpoch 17/30\nTrain Loss1: 0.10064387321472168\nTrain Loss2: 0.10524799823760986\nTrain Loss AU: 0.2719694137573242\nTrain Loss EU: 0.35936014652252196\nTrain DSC: [0.7844587564468384]\nValidation Loss1: 0.20214340209960938\nValidation Loss2: 0.285519962310791\nValidation Loss AU: 0.3423961639404297\nValidation Loss EU: 0.4128096389770508\nValidation DSC: [0.5624952912330627]\n\nEpoch 18/30\nTrain Loss1: 0.09924491643905639\nTrain Loss2: 0.09351062178611755\nTrain Loss AU: 0.27516627311706543\nTrain Loss EU: 0.36767280101776123\nTrain DSC: [0.7879189252853394]\nValidation Loss1: 0.3319675827026367\nValidation Loss2: 0.38858619689941404\nValidation Loss AU: 0.46351776123046873\nValidation Loss EU: 0.5563532638549805\nValidation DSC: [0.2796894609928131]\n\nEpoch 19/30\nTrain Loss1: 0.10275439023971558\nTrain Loss2: 0.1388545513153076\nTrain Loss AU: 0.26062037944793703\nTrain Loss EU: 0.3655289888381958\nTrain DSC: [0.7780978679656982]\nValidation Loss1: 0.2542210960388184\nValidation Loss2: 0.3338772964477539\nValidation Loss AU: 0.48182876586914064\nValidation Loss EU: 0.5726580047607421\nValidation DSC: [0.4582519233226776]\n\nEpoch 20/30\nTrain Loss1: 0.10216840505599975\nTrain Loss2: 0.11491541862487793\nTrain Loss AU: 0.2782201528549194\nTrain Loss EU: 0.366896915435791\nTrain DSC: [0.7795228362083435]\nValidation Loss1: 0.14364745140075683\nValidation Loss2: 0.21307292938232422\nValidation Loss AU: 0.3237798309326172\nValidation Loss EU: 0.39918701171875\nValidation DSC: [0.6926136612892151]\n\nEpoch 21/30\nTrain Loss1: 0.1024277687072754\nTrain Loss2: 0.10121102333068847\nTrain Loss AU: 0.27559409141540525\nTrain Loss EU: 0.36360437870025636\nTrain DSC: [0.7774332761764526]\nValidation Loss1: 0.15203625679016114\nValidation Loss2: 0.23282407760620116\nValidation Loss AU: 0.32030067443847654\nValidation Loss EU: 0.39441909790039065\nValidation DSC: [0.6687625646591187]\n\nEpoch 22/30\nTrain Loss1: 0.09814227819442749\nTrain Loss2: 0.10545260906219482\nTrain Loss AU: 0.26835289001464846\nTrain Loss EU: 0.36212940216064454\nTrain DSC: [0.7841886878013611]\nValidation Loss1: 0.22846632003784179\nValidation Loss2: 0.3043894386291504\nValidation Loss AU: 0.3608721160888672\nValidation Loss EU: 0.4321305465698242\nValidation DSC: [0.5000230669975281]\n\nEpoch 23/30\nTrain Loss1: 0.1016879677772522\nTrain Loss2: 0.12182444334030151\nTrain Loss AU: 0.26985361576080324\nTrain Loss EU: 0.37205958366394043\nTrain DSC: [0.7768980264663696]\nValidation Loss1: 0.16651763916015624\nValidation Loss2: 0.24245119094848633\nValidation Loss AU: 0.327314453125\nValidation Loss EU: 0.4063085174560547\nValidation DSC: [0.6325674653053284]\n\nEpoch 24/30\nTrain Loss1: 0.09673860073089599\nTrain Loss2: 0.10348786115646362\nTrain Loss AU: 0.2731297731399536\nTrain Loss EU: 0.3656562328338623\nTrain DSC: [0.7852030992507935]\nValidation Loss1: 0.14822763442993164\nValidation Loss2: 0.21725927352905272\nValidation Loss AU: 0.3145528030395508\nValidation Loss EU: 0.3981775283813477\nValidation DSC: [0.6728855967521667]\n\nEpoch 25/30\nTrain Loss1: 0.09501837491989136\nTrain Loss2: 0.09470877647399903\nTrain Loss AU: 0.2708711862564087\nTrain Loss EU: 0.3604401111602783\nTrain DSC: [0.7894409894943237]\nValidation Loss1: 0.2054995346069336\nValidation Loss2: 0.286009578704834\nValidation Loss AU: 0.34065826416015627\nValidation Loss EU: 0.41451522827148435\nValidation DSC: [0.5546335577964783]\n\nEpoch 26/30\nTrain Loss1: 0.09215580224990845\nTrain Loss2: 0.09649741649627686\nTrain Loss AU: 0.27039165496826173\nTrain Loss EU: 0.36602737903594973\nTrain DSC: [0.7959088087081909]\nValidation Loss1: 0.18946784973144531\nValidation Loss2: 0.2690141296386719\nValidation Loss AU: 0.3445534896850586\nValidation Loss EU: 0.41846519470214844\nValidation DSC: [0.5884540677070618]\n\nEpoch 27/30\nTrain Loss1: 0.08807030320167542\nTrain Loss2: 0.10159906148910522\nTrain Loss AU: 0.26930224895477295\nTrain Loss EU: 0.36722793579101565\nTrain DSC: [0.8041288256645203]\nValidation Loss1: 0.14873486518859863\nValidation Loss2: 0.22094764709472656\nValidation Loss AU: 0.3205545806884766\nValidation Loss EU: 0.3958719253540039\nValidation DSC: [0.6723275184631348]\n\nEpoch 28/30\nTrain Loss1: 0.08583821654319763\nTrain Loss2: 0.08819421529769897\nTrain Loss AU: 0.26993870735168457\nTrain Loss EU: 0.361828875541687\nTrain DSC: [0.8090750575065613]\nValidation Loss1: 0.13775287628173827\nValidation Loss2: 0.20882219314575196\nValidation Loss AU: 0.3122115135192871\nValidation Loss EU: 0.38908477783203127\nValidation DSC: [0.6953521966934204]\n\nEpoch 29/30\nTrain Loss1: 0.08698147535324097\nTrain Loss2: 0.09655860662460328\nTrain Loss AU: 0.2721713542938232\nTrain Loss EU: 0.36067469120025636\nTrain DSC: [0.8055901527404785]\nValidation Loss1: 0.15792473793029785\nValidation Loss2: 0.23624366760253906\nValidation Loss AU: 0.3159461975097656\nValidation Loss EU: 0.393609504699707\nValidation DSC: [0.6515161395072937]\n\nEpoch 30/30\nTrain Loss1: 0.08564808368682861\nTrain Loss2: 0.08057979941368103\nTrain Loss AU: 0.2678672790527344\nTrain Loss EU: 0.3616042613983154\nTrain DSC: [0.8105600476264954]\nValidation Loss1: 0.24362092971801758\nValidation Loss2: 0.3223199462890625\nValidation Loss AU: 0.38679931640625\nValidation Loss EU: 0.46088123321533203\nValidation DSC: [0.468912273645401]\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675184409852
        }
      },
      "id": "22747d54-19fe-4441-bd5e-adb5a4ee829b"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0cbdf8aa-35f3-4f1e-a322-03999f31afdd"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": false,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "shapeworks"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "shapeworks",
      "language": "python",
      "display_name": "Python (shapeworks)"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}