{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import gc\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import scipy.ndimage as ndimage\n",
        "import shapeworks as sw\n",
        "import DeepSSMUtils\n",
        "from DeepSSMUtils import model\n",
        "import nrrd\n",
        "import torchio as tio\n",
        "import monai\n",
        "import nibabel as nib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, positive=False):\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n/anaconda/envs/shapeworks/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  EPS = np.finfo(np.float).eps\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1677359879761
        },
        "id": "8246ca62",
        "scrolled": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "id": "8246ca62"
    },
    {
      "cell_type": "code",
      "source": [
        "city = 'Beijing_Zang'\n",
        "IMAGE_DIR = f'../dataset/{city}/MRI'\n",
        "MASK_DIR = f'../dataset/{city}/Ventricles3'\n",
        "num_classes = 2\n",
        "TRAIN_SIZE = 50\n",
        "TEST_SIZE = 20\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "output_dir = f'../results/{city}_useless/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677359880121
        }
      },
      "id": "fe9e2ac9"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_cuda_memory():\n",
        "    t = torch.cuda.get_device_properties(0).total_memory\n",
        "    r = torch.cuda.memory_reserved(0)\n",
        "    a = torch.cuda.memory_allocated(0)\n",
        "    f = r-a  # free inside reserved\n",
        "    print('Total:     {:0.2f} GiB'.format(t / 2**30))\n",
        "    print('Reserved:  {:0.2f} GiB'.format(r / 2**30))\n",
        "    print('Allocated: {:0.2f} GiB'.format(a / 2**30))\n",
        "    print('Free:      {:0.2f} GiB'.format(f / 2**30))\n",
        "\n",
        "show_cuda_memory()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total:     11.17 GiB\nReserved:  0.00 GiB\nAllocated: 0.00 GiB\nFree:      0.00 GiB\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677359880586
        }
      },
      "id": "1b1daaed-0d36-4cca-b9fa-6fa73ecf4a6d"
    },
    {
      "cell_type": "code",
      "source": [
        "deepssm_project = 'DeepSSM_rw1'\n",
        "explained_var = 90\n",
        "\n",
        "deepssm_dir = f'../dataset/All/Ventricles_64_3_cleaned/{deepssm_project}'\n",
        "model_path = f'{deepssm_dir}/DeepSSM{explained_var}.json'\n",
        "# state_path = f'{deepssm_dir}/DeepSSM{explained_var}/best_model.torch'\n",
        "state_path = f'DeepSSM{explained_var}/best_model.torch'\n",
        "\n",
        "deepssm = model.DeepSSMNet(model_path).to(DEVICE)\n",
        "deepssm.load_state_dict(torch.load(state_path))\n",
        "for param in deepssm.parameters():\n",
        "    param.requires_grad = False\n",
        "deepssm.eval()\n",
        "\n",
        "std_PCA = np.load(f'{deepssm_dir}/torch_loaders{explained_var}/std_PCA.npy').reshape(1, -1)\n",
        "std_PCA /= std_PCA.sum()\n",
        "std_PCA = torch.Tensor(std_PCA).to(DEVICE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLP layers: 192 -> 96 -> 48 -> 23\n"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'DeepSSM90/best_model.torch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4012/4012744776.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdeepssm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepSSMNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdeepssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeepssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/shapeworks/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/shapeworks/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/shapeworks/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DeepSSM90/best_model.torch'"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677359883520
        }
      },
      "id": "042183cb-47c3-4a3f-86a6-34feb6b238c0"
    },
    {
      "cell_type": "code",
      "source": [
        "mask256_dir = f'../dataset/{city}/Ventricles_256_3'\n",
        "\n",
        "centers = np.zeros((TRAIN_SIZE+TEST_SIZE, 3), dtype=int)\n",
        "pca_scores = []\n",
        "corr_outs = []\n",
        "for i, path in enumerate(tqdm(sorted(glob(f'{mask256_dir}/*.nrrd'))[:TRAIN_SIZE+TEST_SIZE])):\n",
        "    mask = nrrd.read(path)[0]\n",
        "    centers[i] = ndimage.center_of_mass(mask)\n",
        "    a, b, c = centers[i]\n",
        "    pca_loading, corr_out = deepssm(\n",
        "        torch.from_numpy(mask[None, None, a-32:a+32, b-32:b+32, c-32:c+32]).to(DEVICE).float()\n",
        "    )\n",
        "    pca_scores.append(pca_loading[0])\n",
        "    corr_outs.append(corr_out)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 70/70 [01:02<00:00,  1.13it/s]\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1677359950554
        }
      },
      "id": "4c16e520-205b-4c64-83c3-14c6c80411d3"
    },
    {
      "cell_type": "code",
      "source": [
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.segmentation = monai.networks.nets.UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            channels=(32, 64, 128, 256, 512),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            norm=monai.networks.layers.Norm.BATCH,\n",
        "        )\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.ste = StraightThroughEstimator()\n",
        "\n",
        "    def forward(self, x, i):\n",
        "        mask = self.segmentation(x) # (1, C, 256, 256, 256)\n",
        "        mask = self.softmax(mask) # (1, C, 256, 256, 256)\n",
        "        binary_mask = self.ste(mask - 0.5)\n",
        "\n",
        "        np_mask = binary_mask[0, 1].detach().cpu().numpy()\n",
        "        if np.any(np_mask):\n",
        "            a, b, c = ndimage.center_of_mass(np_mask)\n",
        "            a, b, c = int(a), int(b), int(c)\n",
        "            out = False\n",
        "            for j in [a, b, c]:\n",
        "                if j - 32 < 0 or j + 32 > 256:\n",
        "                    out = True\n",
        "                    break\n",
        "            if out:\n",
        "                a, b, c = centers[i]\n",
        "        else:\n",
        "            a, b, c = centers[i]\n",
        "\n",
        "        # a, b, c = centers[i]\n",
        "\n",
        "        binary_mask = binary_mask[:, 1:2, a-32:a+32, b-32:b+32, c-32:c+32]\n",
        "        dist_params, _ = deepssm(binary_mask) # (1, PCs)\n",
        "        return mask, dist_params"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1677359950776
        }
      },
      "id": "127d580c"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subjects(image_dir, mask_dir):\n",
        "    subjects = []\n",
        "    for i, image_path in enumerate(tqdm(sorted(glob(f'{image_dir}/*.nii.gz'))[:TRAIN_SIZE+TEST_SIZE], desc='Creating Subjects')):\n",
        "        filename = image_path.split('/')[-1]\n",
        "        mask_path = f'{mask_dir}/{filename}'\n",
        "        subject = tio.Subject(\n",
        "            t1=tio.ScalarImage(\n",
        "                image_path\n",
        "            ),\n",
        "            label=tio.LabelMap(mask_path),\n",
        "        )\n",
        "        subjects.append(subject)\n",
        "    return subjects\n",
        "\n",
        "all_subjects = get_subjects(IMAGE_DIR, MASK_DIR)\n",
        "subjects = {\n",
        "    'train': all_subjects[:TRAIN_SIZE],\n",
        "    'validation': all_subjects[TRAIN_SIZE:],\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Creating Subjects: 100%|██████████| 70/70 [00:00<00:00, 83.07it/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1677359953025
        },
        "id": "iwKH3_Dd1ehr"
      },
      "id": "iwKH3_Dd1ehr"
    },
    {
      "cell_type": "code",
      "source": [
        "# spatial = tio.OneOf(\n",
        "#     {tio.RandomAffine(degrees=(-3, 3), translation=(-0.1, 0.1)): 1.0},\n",
        "#     p=0.75,\n",
        "# )\n",
        "\n",
        "resample = tio.Compose([\n",
        "    tio.Resample(1),\n",
        "    tio.CropOrPad((176,240,224)),\n",
        "])\n",
        "\n",
        "signal = tio.Compose([ \n",
        "    tio.RescaleIntensity(percentiles=(0.1, 99.9), out_min_max=(0, 1)),\n",
        "])\n",
        "\n",
        "def get_transform(std):\n",
        "    transform = {\n",
        "        'train': tio.Compose([\n",
        "            # spatial, \n",
        "            resample, \n",
        "            signal,\n",
        "        ]),\n",
        "        'validation': tio.Compose([\n",
        "            resample, \n",
        "            signal,\n",
        "        ]),\n",
        "    }\n",
        "    return transform\n",
        "\n",
        "def get_dataloader(transform):\n",
        "    dataloader = dict()\n",
        "    for mode in ['train', 'validation']:\n",
        "        dataloader[mode] = torch.utils.data.DataLoader(\n",
        "            tio.SubjectsDataset(\n",
        "                subjects[mode], \n",
        "                transform=transform[mode]\n",
        "            ),\n",
        "            batch_size=BATCH_SIZE, \n",
        "            num_workers=os.cpu_count(),\n",
        "            shuffle=False,\n",
        "        )\n",
        "    return dataloader"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1677359953249
        },
        "id": "RWe0BZebDKLq"
      },
      "id": "RWe0BZebDKLq"
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loss_dice, loss_mse, metric, losses1, losses2, dscs, std, dataloader, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mean_loss1, mean_loss2, mean_loss_au, mean_loss_eu = 0, 0, 0, 0\n",
        "        for i, subject in enumerate(dataloader['validation']):\n",
        "            image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "            label = subject['label'][tio.DATA].to(DEVICE)\n",
        "\n",
        "            mask, [mu, v, alpha, beta] = model(image, TRAIN_SIZE+i)\n",
        "            one_hot_label = monai.networks.utils.one_hot(\n",
        "                label, num_classes=num_classes, dim=1\n",
        "            ).to(DEVICE)\n",
        "                \n",
        "            loss1 = loss_dice(mask, one_hot_label)\n",
        "            loss2 = 0#torch.sum(std_PCA * (mu - pca_scores[TRAIN_SIZE+i]) ** 2)\n",
        "            loss_au = torch.mean(beta / (alpha - 1))\n",
        "            loss_eu = torch.mean(beta / (v * (alpha - 1)))\n",
        "\n",
        "            # loss2 = torch.sum(std_PCA * pca ** 2)\n",
        "            # loss2 = torch.mean(pca ** 2)\n",
        "            # loss2 = torch.mean((corr_out - corr_outs[TRAIN_SIZE+i]) ** 2)\n",
        "\n",
        "            mean_loss1 += loss1 * image.shape[0]\n",
        "            mean_loss2 += loss2 * image.shape[0]\n",
        "            mean_loss_au += loss_au * image.shape[0]\n",
        "            mean_loss_eu += loss_eu * image.shape[0]\n",
        "\n",
        "            one_hot_pred = monai.networks.utils.one_hot(\n",
        "                torch.argmax(mask, dim=1, keepdim=True), \n",
        "                num_classes=num_classes, \n",
        "                dim=1\n",
        "            ).to(DEVICE)\n",
        "            metric(one_hot_pred, one_hot_label)\n",
        "            \n",
        "            # if i % 10 == 0:\n",
        "            #     if not os.path.exists(f'{output_dir}valimage{i}_label.nrrd'):\n",
        "            #         nrrd.write(f'{output_dir}valimage{i}_label.nrrd', label.detach().cpu().numpy()[0, 0])\n",
        "            #     nrrd.write(f'{output_dir}valimage{i}_prob_epoch{epoch+1}.nrrd', binary_mask.detach().cpu().numpy()[0, 0])\n",
        "\n",
        "            del image, label, mask, one_hot_label, one_hot_pred, loss1, loss2, loss_au, loss_eu, mu, v, alpha, beta\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        mean_loss1 = mean_loss1.item() / TEST_SIZE\n",
        "        mean_loss2 = mean_loss2.item() / TEST_SIZE\n",
        "        mean_loss_au = mean_loss_au.item() / TEST_SIZE\n",
        "        mean_loss_eu = mean_loss_eu.item() / TEST_SIZE\n",
        "        print(f'Validation Loss1: {mean_loss1}')\n",
        "        print(f'Validation Loss2: {mean_loss2}')\n",
        "        print(f'Validation Loss AU: {mean_loss_au}')\n",
        "        print(f'Validation Loss EU: {mean_loss_eu}')\n",
        "\n",
        "        mean_dsc = metric.aggregate().tolist()\n",
        "        metric.reset()\n",
        "        print(f'Validation DSC: {mean_dsc}\\n')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360020580
        }
      },
      "id": "32b9f1a8-b3e3-4f8a-9425-d55fd64735c0"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_epochs, dataloader, std, weight, lr, save):\n",
        "    losses1, losses2, dscs = [defaultdict(list) for _ in range(3)]\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
        "    loss_dice = monai.losses.DiceLoss(squared_pred=True).to(DEVICE)\n",
        "    loss_mse = torch.nn.MSELoss().to(DEVICE)\n",
        "    metric = monai.metrics.DiceMetric(include_background=False, reduction='mean_batch')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}')\n",
        "        model.train()\n",
        "\n",
        "        mean_loss1, mean_loss2, mean_loss_au, mean_loss_eu = 0, 0, 0, 0\n",
        "        for i, subject in enumerate(dataloader['train']):\n",
        "            \n",
        "            image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "            label = subject['label'][tio.DATA].to(DEVICE)\n",
        "            one_hot_label = monai.networks.utils.one_hot(\n",
        "                label, num_classes=num_classes, dim=1\n",
        "            ).to(DEVICE)\n",
        "        \n",
        "            mask, [mu, v, alpha, beta] = model(image, i)\n",
        "            loss1 = loss_dice(mask, one_hot_label)\n",
        "            loss2 = 0#torch.sum(std_PCA * (mu - pca_scores[i]) ** 2)\n",
        "            loss_au = torch.mean(beta / (alpha - 1))\n",
        "            loss_eu = torch.mean(beta / (v * (alpha - 1)))\n",
        "\n",
        "            # loss2 = loss_mse(pca, pca_scores[i])\n",
        "            # loss2 = torch.sum(std_PCA * pca ** 2)\n",
        "            # loss2 = torch.mean(pca ** 2)\n",
        "            # loss2 = torch.mean((corr_out - corr_outs[i]) ** 2)\n",
        "\n",
        "            loss = loss1 + weight * (loss2 + loss_au + loss_eu)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            mean_loss1 += loss1 * image.shape[0]\n",
        "            mean_loss2 += loss2 * image.shape[0]\n",
        "            mean_loss_au += loss_au * image.shape[0]\n",
        "            mean_loss_eu += loss_eu * image.shape[0]\n",
        "\n",
        "            one_hot_pred = monai.networks.utils.one_hot(\n",
        "                torch.argmax(mask, dim=1, keepdim=True), \n",
        "                num_classes=num_classes, \n",
        "                dim=1\n",
        "            ).to(DEVICE)\n",
        "            metric(one_hot_pred, one_hot_label)\n",
        "\n",
        "            # if i % 10 == 0:\n",
        "            #     if not os.path.exists(f'{output_dir}trainimage{i}_label.nrrd'):\n",
        "            #         nrrd.write(f'{output_dir}trainimage{i}_label.nrrd', label.detach().cpu().numpy()[0, 0])\n",
        "            #     nrrd.write(f'{output_dir}trainimage{i}_prob_epoch{epoch+1}.nrrd', binary_mask.detach().cpu().numpy()[0, 0])\n",
        "\n",
        "            del image, label, mask, one_hot_label, one_hot_pred, loss, loss1, loss2, loss_au, loss_eu, mu, v, alpha, beta\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        mean_loss1 = mean_loss1.item() / TRAIN_SIZE\n",
        "        mean_loss2 = mean_loss2.item() / TRAIN_SIZE\n",
        "        mean_loss_au = mean_loss_au.item() / TRAIN_SIZE\n",
        "        mean_loss_eu = mean_loss_eu.item() / TRAIN_SIZE\n",
        "        print(f'Train Loss1: {mean_loss1}')\n",
        "        print(f'Train Loss2: {mean_loss2}')\n",
        "        print(f'Train Loss AU: {mean_loss_au}')\n",
        "        print(f'Train Loss EU: {mean_loss_eu}')\n",
        "\n",
        "        mean_dsc = metric.aggregate().tolist()\n",
        "        metric.reset()\n",
        "        print(f'Train DSC: {mean_dsc}')\n",
        "\n",
        "        validate(model, loss_dice, loss_mse, metric, losses1, losses2, dscs, std, dataloader, epoch)\n",
        "\n",
        "        if save and (epoch+1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), f'{output_dir}model_epoch{epoch+1}.pth')"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360021424
        }
      },
      "id": "bf064a15-780b-401a-9689-162ee97f7899"
    },
    {
      "cell_type": "code",
      "source": [
        "std = 0\n",
        "transform = get_transform(std=std)\n",
        "dataloader = get_dataloader(transform)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677359981187
        }
      },
      "id": "3db80ece-41da-45b6-9d6d-bc6f42dd6a0b"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(DEVICE)\n",
        "# model.load_state_dict(torch.load(f'{output_dir}model_epoch40.pth'))\n",
        "train(model, n_epochs=50, dataloader=dataloader, std=std, weight=0, lr=3e-4, save=True)\n",
        "\n",
        "# torch.save(model.state_dict(), f'{output_dir}/UNet_std1000.pth')\n",
        "\n",
        "# del model, transform, dataloader, losses1, losses2, dscs\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/50\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'item'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4012/3358902047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.load_state_dict(torch.load(f'{output_dir}model_epoch40.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# torch.save(model.state_dict(), f'{output_dir}/UNet_std1000.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_4012/3943577372.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, dataloader, std, weight, lr, save)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmean_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_loss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mmean_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_loss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mmean_loss_au\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_loss_au\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmean_loss_eu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_loss_eu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360095366
        }
      },
      "id": "22747d54-19fe-4441-bd5e-adb5a4ee829b"
    },
    {
      "cell_type": "code",
      "source": [
        "del model#, transform, dataloader, losses1, losses2, dscs\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for weight in [0, 0.1, 0.2]:\n",
        "    model = Model().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(f'{output_dir}model_epoch30.pth'))\n",
        "    train(model, n_epochs=30, dataloader=dataloader, std=std, weight=weight, lr=3e-4 * 0.99 ** 30, save=False)\n",
        "\n",
        "    # torch.save(model.state_dict(), f'{output_dir}/UNet_std1000.pth')\n",
        "\n",
        "    del model#, transform, dataloader, losses1, losses2, dscs\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/30\nTrain Loss1: 0.11611012220382691\nTrain Loss2: 0.20085442066192627\nTrain Loss AU: 0.6561747074127198\nTrain Loss EU: 0.8293649673461914\nTrain DSC: [0.7494243383407593]\nValidation Loss1: 0.12880796432495117\nValidation Loss2: 0.16747303009033204\nValidation Loss AU: 0.6543470764160156\nValidation Loss EU: 0.8007719421386719\nValidation DSC: [0.7286714315414429]\n\nEpoch 2/30\nTrain Loss1: 0.09257615208625794\nTrain Loss2: 0.139526891708374\nTrain Loss AU: 0.6460845470428467\nTrain Loss EU: 0.7944520473480224\nTrain DSC: [0.8082050085067749]\nValidation Loss1: 0.19059579849243163\nValidation Loss2: 0.1620872688293457\nValidation Loss AU: 0.6901491546630859\nValidation Loss EU: 0.8573956298828125\nValidation DSC: [0.5753125548362732]\n\nEpoch 3/30\nTrain Loss1: 0.07809499502182007\nTrain Loss2: 0.11606744527816773\nTrain Loss AU: 0.6399372100830079\nTrain Loss EU: 0.784183931350708\nTrain DSC: [0.8350142240524292]\nValidation Loss1: 0.1820522117614746\nValidation Loss2: 0.1706673812866211\nValidation Loss AU: 0.6838882446289063\nValidation Loss EU: 0.8458919525146484\nValidation DSC: [0.5825459361076355]\n\nEpoch 4/30\nTrain Loss1: 0.06869273185729981\nTrain Loss2: 0.08808495998382568\nTrain Loss AU: 0.6177612781524658\nTrain Loss EU: 0.7407551765441894\nTrain DSC: [0.8564494848251343]\nValidation Loss1: 0.13478710174560546\nValidation Loss2: 0.15948988914489745\nValidation Loss AU: 0.6380099105834961\nValidation Loss EU: 0.7735029602050781\nValidation DSC: [0.7021120190620422]\n\nEpoch 5/30\nTrain Loss1: 0.0631296157836914\nTrain Loss2: 0.07174399495124817\nTrain Loss AU: 0.6185433387756347\nTrain Loss EU: 0.7605735778808593\nTrain DSC: [0.8676273226737976]\nValidation Loss1: 0.12588241577148437\nValidation Loss2: 0.15480756759643555\nValidation Loss AU: 0.6468668365478516\nValidation Loss EU: 0.7830210113525391\nValidation DSC: [0.7135090827941895]\n\nEpoch 6/30\nTrain Loss1: 0.05599242448806763\nTrain Loss2: 0.06108337640762329\nTrain Loss AU: 0.6206998348236084\nTrain Loss EU: 0.7523269653320312\nTrain DSC: [0.882973313331604]\nValidation Loss1: 0.15736400604248046\nValidation Loss2: 0.1640436553955078\nValidation Loss AU: 0.6712352752685546\nValidation Loss EU: 0.8278028106689453\nValidation DSC: [0.6393357515335083]\n\nEpoch 7/30\nTrain Loss1: 0.056244170665740965\nTrain Loss2: 0.054922640323638916\nTrain Loss AU: 0.6220056533813476\nTrain Loss EU: 0.748845386505127\nTrain DSC: [0.8777780532836914]\nValidation Loss1: 0.12026663780212403\nValidation Loss2: 0.15327982902526854\nValidation Loss AU: 0.6462865447998047\nValidation Loss EU: 0.7813175201416016\nValidation DSC: [0.7217143177986145]\n\nEpoch 8/30\nTrain Loss1: 0.06301599740982056\nTrain Loss2: 0.08043549060821534\nTrain Loss AU: 0.6198655128479004\nTrain Loss EU: 0.7489433288574219\nTrain DSC: [0.8581289052963257]\nValidation Loss1: 0.17485326766967774\nValidation Loss2: 0.16776004791259766\nValidation Loss AU: 0.6819422912597656\nValidation Loss EU: 0.8434236145019531\nValidation DSC: [0.5996714234352112]\n\nEpoch 9/30\nTrain Loss1: 0.06862042546272278\nTrain Loss2: 0.09342362880706787\nTrain Loss AU: 0.6372951984405517\nTrain Loss EU: 0.7917147159576416\nTrain DSC: [0.8410053253173828]\nValidation Loss1: 0.12787731170654296\nValidation Loss2: 0.17400602340698243\nValidation Loss AU: 0.6482701873779297\nValidation Loss EU: 0.7909519958496094\nValidation DSC: [0.7092671990394592]\n\nEpoch 10/30\nTrain Loss1: 0.0578667163848877\nTrain Loss2: 0.05487355589866638\nTrain Loss AU: 0.6314858436584473\nTrain Loss EU: 0.7685442924499511\nTrain DSC: [0.8711532354354858]\nValidation Loss1: 0.22269292831420898\nValidation Loss2: 0.18204723358154296\nValidation Loss AU: 0.7082437133789062\nValidation Loss EU: 0.8904914855957031\nValidation DSC: [0.48894912004470825]\n\nEpoch 11/30\nTrain Loss1: 0.047185343503952024\nTrain Loss2: 0.04689784049987793\nTrain Loss AU: 0.6218464851379395\nTrain Loss EU: 0.7392256736755372\nTrain DSC: [0.9023633003234863]\nValidation Loss1: 0.13643575668334962\nValidation Loss2: 0.15851983070373535\nValidation Loss AU: 0.6541899108886718\nValidation Loss EU: 0.7973928070068359\nValidation DSC: [0.68473219871521]\n\nEpoch 12/30\nTrain Loss1: 0.049159121513366696\nTrain Loss2: 0.049112656712532045\nTrain Loss AU: 0.6233432769775391\nTrain Loss EU: 0.7583073139190674\nTrain DSC: [0.8904021978378296]\nValidation Loss1: 0.14965380668640138\nValidation Loss2: 0.1594938373565674\nValidation Loss AU: 0.6645084381103515\nValidation Loss EU: 0.809041748046875\nValidation DSC: [0.6552379131317139]\n\nEpoch 13/30\nTrain Loss1: 0.04518665671348572\nTrain Loss2: 0.05036972761154175\nTrain Loss AU: 0.6274627685546875\nTrain Loss EU: 0.7702461242675781\nTrain DSC: [0.9018046259880066]\nValidation Loss1: 0.15135849952697755\nValidation Loss2: 0.21991222381591796\nValidation Loss AU: 0.7086371612548829\nValidation Loss EU: 0.9172412872314453\nValidation DSC: [0.6715173125267029]\n\nEpoch 14/30\nTrain Loss1: 0.04519168138504028\nTrain Loss2: 0.04893574118614197\nTrain Loss AU: 0.6184203147888183\nTrain Loss EU: 0.750898790359497\nTrain DSC: [0.8993688821792603]\nValidation Loss1: 0.1199386978149414\nValidation Loss2: 0.14439116477966307\nValidation Loss AU: 0.6451503753662109\nValidation Loss EU: 0.7818876647949219\nValidation DSC: [0.7219045162200928]\n\nEpoch 15/30\nTrain Loss1: 0.04143534600734711\nTrain Loss2: 0.048107415437698364\nTrain Loss AU: 0.627894401550293\nTrain Loss EU: 0.7616700172424317\nTrain DSC: [0.9102643132209778]\nValidation Loss1: 0.1498288917541504\nValidation Loss2: 0.16920629501342774\nValidation Loss AU: 0.6640394592285156\nValidation Loss EU: 0.810283203125\nValidation DSC: [0.6520814299583435]\n\nEpoch 16/30\nTrain Loss1: 0.040793991088867186\nTrain Loss2: 0.03704176247119904\nTrain Loss AU: 0.6160534858703614\nTrain Loss EU: 0.7462757587432861\nTrain DSC: [0.9085544347763062]\nValidation Loss1: 0.1546270179748535\nValidation Loss2: 0.16329090118408204\nValidation Loss AU: 0.6659563446044922\nValidation Loss EU: 0.8116082763671875\nValidation DSC: [0.6430928707122803]\n\nEpoch 17/30\nTrain Loss1: 0.03801563680171967\nTrain Loss2: 0.048770496249198915\nTrain Loss AU: 0.5999773025512696\nTrain Loss EU: 0.7112168312072754\nTrain DSC: [0.9159242510795593]\nValidation Loss1: 0.15758851051330566\nValidation Loss2: 0.15394659996032714\nValidation Loss AU: 0.6646503448486328\nValidation Loss EU: 0.8130404663085937\nValidation DSC: [0.637788712978363]\n\nEpoch 18/30\nTrain Loss1: 0.038377541303634646\nTrain Loss2: 0.0511039674282074\nTrain Loss AU: 0.6089164257049561\nTrain Loss EU: 0.7443368911743165\nTrain DSC: [0.914439857006073]\nValidation Loss1: 0.11560675621032715\nValidation Loss2: 0.16027212142944336\nValidation Loss AU: 0.6419479370117187\nValidation Loss EU: 0.7790153503417969\nValidation DSC: [0.7327917218208313]\n\nEpoch 19/30\nTrain Loss1: 0.033245119452476504\nTrain Loss2: 0.035087418556213376\nTrain Loss AU: 0.627387523651123\nTrain Loss EU: 0.7595083713531494\nTrain DSC: [0.9302806854248047]\nValidation Loss1: 0.1470360279083252\nValidation Loss2: 0.16816896438598633\nValidation Loss AU: 0.6660210418701172\nValidation Loss EU: 0.8173119354248047\nValidation DSC: [0.6583666801452637]\n\nEpoch 20/30\nTrain Loss1: 0.02892281711101532\nTrain Loss2: 0.027301844954490662\nTrain Loss AU: 0.6088043689727783\nTrain Loss EU: 0.7339523315429688\nTrain DSC: [0.9397778511047363]\nValidation Loss1: 0.20418956756591797\nValidation Loss2: 0.19045011520385743\nValidation Loss AU: 0.6985060882568359\nValidation Loss EU: 0.873297348022461\nValidation DSC: [0.5391538739204407]\n\nEpoch 21/30\nTrain Loss1: 0.029395151138305663\nTrain Loss2: 0.029494303464889526\nTrain Loss AU: 0.6152017116546631\nTrain Loss EU: 0.7420050144195557\nTrain DSC: [0.9360643625259399]\nValidation Loss1: 0.11795178413391114\nValidation Loss2: 0.16312957763671876\nValidation Loss AU: 0.645963134765625\nValidation Loss EU: 0.7828321838378907\nValidation DSC: [0.7261607646942139]\n\nEpoch 22/30\nTrain Loss1: 0.02575514614582062\nTrain Loss2: 0.03172720968723297\nTrain Loss AU: 0.6099806785583496\nTrain Loss EU: 0.7332795143127442\nTrain DSC: [0.9483242034912109]\nValidation Loss1: 0.12847025871276854\nValidation Loss2: 0.14573511123657226\nValidation Loss AU: 0.6514891052246093\nValidation Loss EU: 0.7840812683105469\nValidation DSC: [0.7047783732414246]\n\nEpoch 23/30\nTrain Loss1: 0.022577911615371704\nTrain Loss2: 0.014885970950126648\nTrain Loss AU: 0.6129638671875\nTrain Loss EU: 0.7402456760406494\nTrain DSC: [0.9565130472183228]\nValidation Loss1: 0.15374082565307617\nValidation Loss2: 0.1640017509460449\nValidation Loss AU: 0.6655191802978515\nValidation Loss EU: 0.8101859283447266\nValidation DSC: [0.6506696939468384]\n\nEpoch 24/30\nTrain Loss1: 0.021010100841522217\nTrain Loss2: 0.023567791283130645\nTrain Loss AU: 0.6120811939239502\nTrain Loss EU: 0.7439226627349853\nTrain DSC: [0.9595394134521484]\nValidation Loss1: 0.13388438224792482\nValidation Loss2: 0.15702528953552247\nValidation Loss AU: 0.6474510192871094\nValidation Loss EU: 0.7802005004882813\nValidation DSC: [0.690589427947998]\n\nEpoch 25/30\nTrain Loss1: 0.019238820672035216\nTrain Loss2: 0.014898578822612762\nTrain Loss AU: 0.6099172115325928\nTrain Loss EU: 0.7355703830718994\nTrain DSC: [0.9651654958724976]\nValidation Loss1: 0.13176010131835938\nValidation Loss2: 0.15183833122253418\nValidation Loss AU: 0.6507138061523438\nValidation Loss EU: 0.787335433959961\nValidation DSC: [0.6949974298477173]\n\nEpoch 26/30\nTrain Loss1: 0.018393707275390626\nTrain Loss2: 0.013855794072151184\nTrain Loss AU: 0.6181599617004394\nTrain Loss EU: 0.7523058414459228\nTrain DSC: [0.9668635129928589]\nValidation Loss1: 0.16295675277709962\nValidation Loss2: 0.16979486465454102\nValidation Loss AU: 0.6657325744628906\nValidation Loss EU: 0.8134945678710938\nValidation DSC: [0.632026195526123]\n\nEpoch 27/30\nTrain Loss1: 0.018763703107833863\nTrain Loss2: 0.022136010229587555\nTrain Loss AU: 0.6137770652770996\nTrain Loss EU: 0.7459983348846435\nTrain DSC: [0.9652042388916016]\nValidation Loss1: 0.12331614494323731\nValidation Loss2: 0.165454158782959\nValidation Loss AU: 0.6451417541503907\nValidation Loss EU: 0.7800590515136718\nValidation DSC: [0.7144415378570557]\n\nEpoch 28/30\nTrain Loss1: 0.017694318294525148\nTrain Loss2: 0.015539923310279846\nTrain Loss AU: 0.6111465930938721\nTrain Loss EU: 0.7388768196105957\nTrain DSC: [0.9672272801399231]\nValidation Loss1: 0.12889857292175294\nValidation Loss2: 0.15668000221252443\nValidation Loss AU: 0.6543983459472656\nValidation Loss EU: 0.7954054260253907\nValidation DSC: [0.7033113241195679]\n\nEpoch 29/30\nTrain Loss1: 0.01659901738166809\nTrain Loss2: 0.014366605877876281\nTrain Loss AU: 0.6200894355773926\nTrain Loss EU: 0.7607744216918946\nTrain DSC: [0.9704662561416626]\nValidation Loss1: 0.1557216739654541\nValidation Loss2: 0.1646560859680176\nValidation Loss AU: 0.6613412475585938\nValidation Loss EU: 0.8017180633544921\nValidation DSC: [0.6491636633872986]\n\nEpoch 30/30\nTrain Loss1: 0.016847026348114014\nTrain Loss2: 0.019343063235282898\nTrain Loss AU: 0.614897632598877\nTrain Loss EU: 0.7484350681304932\nTrain DSC: [0.9693479537963867]\nValidation Loss1: 0.12789295196533204\nValidation Loss2: 0.15496160507202147\nValidation Loss AU: 0.6445926666259766\nValidation Loss EU: 0.7801887512207031\nValidation DSC: [0.7048885226249695]\n\nEpoch 1/30\nTrain Loss1: 0.11145018339157105\nTrain Loss2: 0.13965146541595458\nTrain Loss AU: 0.6552834510803223\nTrain Loss EU: 0.8188095092773438\nTrain DSC: [0.7635865211486816]\nValidation Loss1: 0.1356383419036865\nValidation Loss2: 0.18462913513183593\nValidation Loss AU: 0.6373291015625\nValidation Loss EU: 0.7714326477050781\nValidation DSC: [0.7070064544677734]\n\nEpoch 2/30\nTrain Loss1: 0.10377448797225952\nTrain Loss2: 0.12846344709396362\nTrain Loss AU: 0.6269004344940186\nTrain Loss EU: 0.756502914428711\nTrain DSC: [0.7825215458869934]\nValidation Loss1: 0.21653669357299804\nValidation Loss2: 0.19092485427856445\nValidation Loss AU: 0.6909275817871093\nValidation Loss EU: 0.8565457916259765\nValidation DSC: [0.5237134099006653]\n\nEpoch 3/30\nTrain Loss1: 0.08306750059127807\nTrain Loss2: 0.10727488994598389\nTrain Loss AU: 0.61722731590271\nTrain Loss EU: 0.7399984836578369\nTrain DSC: [0.8258587718009949]\nValidation Loss1: 0.22384668350219727\nValidation Loss2: 0.21414880752563475\nValidation Loss AU: 0.6935419464111328\nValidation Loss EU: 0.8620595550537109\nValidation DSC: [0.4979008436203003]\n\nEpoch 4/30\nTrain Loss1: 0.08072327375411988\nTrain Loss2: 0.08559467792510986\nTrain Loss AU: 0.6075466632843017\nTrain Loss EU: 0.7201127052307129\nTrain DSC: [0.8303194046020508]\nValidation Loss1: 0.1576244354248047\nValidation Loss2: 0.18802375793457032\nValidation Loss AU: 0.6846269989013671\nValidation Loss EU: 0.85701171875\nValidation DSC: [0.6657178997993469]\n\nEpoch 5/30\nTrain Loss1: 0.07456657886505128\nTrain Loss2: 0.08011273741722107\nTrain Loss AU: 0.5899064064025878\nTrain Loss EU: 0.6771218299865722\nTrain DSC: [0.8384577035903931]\nValidation Loss1: 0.15048836708068847\nValidation Loss2: 0.18374073028564453\nValidation Loss AU: 0.6533241271972656\nValidation Loss EU: 0.7867916870117188\nValidation DSC: [0.6631733775138855]\n\nEpoch 6/30\nTrain Loss1: 0.06795921325683593\nTrain Loss2: 0.051042485237121585\nTrain Loss AU: 0.5972902774810791\nTrain Loss EU: 0.6916016101837158\nTrain DSC: [0.8537944555282593]\nValidation Loss1: 0.1389821243286133\nValidation Loss2: 0.18082366943359374\nValidation Loss AU: 0.6500649261474609\nValidation Loss EU: 0.7842716217041016\nValidation DSC: [0.6813291907310486]\n\nEpoch 7/30\nTrain Loss1: 0.06911749839782715\nTrain Loss2: 0.05607074499130249\nTrain Loss AU: 0.589848804473877\nTrain Loss EU: 0.6824297428131103\nTrain DSC: [0.8465713262557983]\nValidation Loss1: 0.14872225761413574\nValidation Loss2: 0.1844619941711426\nValidation Loss AU: 0.6558139038085937\nValidation Loss EU: 0.7936090087890625\nValidation DSC: [0.6581581234931946]\n\nEpoch 8/30\nTrain Loss1: 0.06818469762802123\nTrain Loss2: 0.08096923232078553\nTrain Loss AU: 0.5722560882568359\nTrain Loss EU: 0.6511967182159424\nTrain DSC: [0.8477733731269836]\nValidation Loss1: 0.1339879035949707\nValidation Loss2: 0.16865839004516603\nValidation Loss AU: 0.6330010604858398\nValidation Loss EU: 0.7562805938720704\nValidation DSC: [0.6960955262184143]\n\nEpoch 9/30\nTrain Loss1: 0.06997311115264893\nTrain Loss2: 0.07721269130706787\nTrain Loss AU: 0.5739599704742432\nTrain Loss EU: 0.65719633102417\nTrain DSC: [0.8427596092224121]\nValidation Loss1: 0.1391614246368408\nValidation Loss2: 0.18773895263671875\nValidation Loss AU: 0.6556366729736328\nValidation Loss EU: 0.7937677764892578\nValidation DSC: [0.6852507591247559]\n\nEpoch 10/30\nTrain Loss1: 0.06669145822525024\nTrain Loss2: 0.0684048593044281\nTrain Loss AU: 0.6005120277404785\nTrain Loss EU: 0.6905287742614746\nTrain DSC: [0.8479205965995789]\nValidation Loss1: 0.14330731391906737\nValidation Loss2: 0.1708447265625\nValidation Loss AU: 0.6521012115478516\nValidation Loss EU: 0.7852597808837891\nValidation DSC: [0.6723036170005798]\n\nEpoch 11/30\nTrain Loss1: 0.06058125495910645\nTrain Loss2: 0.059967607259750366\nTrain Loss AU: 0.5540993690490723\nTrain Loss EU: 0.6145110130310059\nTrain DSC: [0.8607997894287109]\nValidation Loss1: 0.2541248321533203\nValidation Loss2: 0.23016407012939452\nValidation Loss AU: 0.7262539672851562\nValidation Loss EU: 0.9269406127929688\nValidation DSC: [0.43378201127052307]\n\nEpoch 12/30\nTrain Loss1: 0.05596228837966919\nTrain Loss2: 0.058158642053604125\nTrain Loss AU: 0.5485215663909913\nTrain Loss EU: 0.6024415969848633\nTrain DSC: [0.8720157742500305]\nValidation Loss1: 0.13003742218017578\nValidation Loss2: 0.17263486862182617\nValidation Loss AU: 0.6434000396728515\nValidation Loss EU: 0.7783472442626953\nValidation DSC: [0.6990922689437866]\n\nEpoch 13/30\nTrain Loss1: 0.05020187497138977\nTrain Loss2: 0.057991969585418704\nTrain Loss AU: 0.5587167739868164\nTrain Loss EU: 0.6200347423553467\nTrain DSC: [0.8875832557678223]\nValidation Loss1: 0.15703914642333985\nValidation Loss2: 0.17376781463623048\nValidation Loss AU: 0.6637137603759765\nValidation Loss EU: 0.8067121124267578\nValidation DSC: [0.6416348218917847]\n\nEpoch 14/30\nTrain Loss1: 0.05048922300338745\nTrain Loss2: 0.04792838394641876\nTrain Loss AU: 0.5487143993377686\nTrain Loss EU: 0.6043761730194092\nTrain DSC: [0.8854178190231323]\nValidation Loss1: 0.15472338676452638\nValidation Loss2: 0.17854543685913085\nValidation Loss AU: 0.6566780090332032\nValidation Loss EU: 0.7959194946289062\nValidation DSC: [0.6467337608337402]\n\nEpoch 15/30\nTrain Loss1: 0.05356817841529846\nTrain Loss2: 0.06095163226127624\nTrain Loss AU: 0.55203218460083\nTrain Loss EU: 0.6100764274597168\nTrain DSC: [0.8766790628433228]\nValidation Loss1: 0.1547813320159912\nValidation Loss2: 0.19255870819091797\nValidation Loss AU: 0.6563590240478515\nValidation Loss EU: 0.7921427917480469\nValidation DSC: [0.6481713056564331]\n\nEpoch 16/30\nTrain Loss1: 0.054403293132781985\nTrain Loss2: 0.08074653148651123\nTrain Loss AU: 0.5570718765258789\nTrain Loss EU: 0.6197152614593506\nTrain DSC: [0.8744775056838989]\nValidation Loss1: 0.12219446182250976\nValidation Loss2: 0.16989059448242189\nValidation Loss AU: 0.6303182220458985\nValidation Loss EU: 0.7481903076171875\nValidation DSC: [0.7193996906280518]\n\nEpoch 17/30\nTrain Loss1: 0.04672910571098328\nTrain Loss2: 0.05342261791229248\nTrain Loss AU: 0.5587209224700928\nTrain Loss EU: 0.6194816112518311\nTrain DSC: [0.8947194218635559]\nValidation Loss1: 0.14919605255126953\nValidation Loss2: 0.17192323684692382\nValidation Loss AU: 0.6639853668212891\nValidation Loss EU: 0.8076309204101563\nValidation DSC: [0.6596527099609375]\n\nEpoch 18/30\nTrain Loss1: 0.0482456237077713\nTrain Loss2: 0.06250953674316406\nTrain Loss AU: 0.547077226638794\nTrain Loss EU: 0.6140327453613281\nTrain DSC: [0.8870752453804016]\nValidation Loss1: 0.12279375076293945\nValidation Loss2: 0.16140710830688476\nValidation Loss AU: 0.6430961608886718\nValidation Loss EU: 0.7716164398193359\nValidation DSC: [0.719532310962677]\n\nEpoch 19/30\nTrain Loss1: 0.04539893567562103\nTrain Loss2: 0.05725201368331909\nTrain Loss AU: 0.5309235572814941\nTrain Loss EU: 0.5712365627288818\nTrain DSC: [0.8962157964706421]\nValidation Loss1: 0.13253596305847168\nValidation Loss2: 0.15888397216796876\nValidation Loss AU: 0.648125\nValidation Loss EU: 0.7779873657226563\nValidation DSC: [0.6990381479263306]\n\nEpoch 20/30\nTrain Loss1: 0.04401943385601044\nTrain Loss2: 0.04948630928993225\nTrain Loss AU: 0.5374412059783935\nTrain Loss EU: 0.5784539222717285\nTrain DSC: [0.8976110219955444]\nValidation Loss1: 0.1394027042388916\nValidation Loss2: 0.172282657623291\nValidation Loss AU: 0.6434226226806641\nValidation Loss EU: 0.7730475616455078\nValidation DSC: [0.6799856424331665]\n\nEpoch 21/30\nTrain Loss1: 0.041068282723426816\nTrain Loss2: 0.05616824626922608\nTrain Loss AU: 0.5234894275665283\nTrain Loss EU: 0.5634040355682373\nTrain DSC: [0.906905472278595]\nValidation Loss1: 0.1659177780151367\nValidation Loss2: 0.18841850280761718\nValidation Loss AU: 0.6636605834960938\nValidation Loss EU: 0.8062194061279296\nValidation DSC: [0.6245940923690796]\n\nEpoch 22/30\nTrain Loss1: 0.03971017599105835\nTrain Loss2: 0.05378593802452088\nTrain Loss AU: 0.5363097667694092\nTrain Loss EU: 0.5803759574890137\nTrain DSC: [0.9111418724060059]\nValidation Loss1: 0.17354970932006836\nValidation Loss2: 0.1925242042541504\nValidation Loss AU: 0.6715039825439453\nValidation Loss EU: 0.8172843933105469\nValidation DSC: [0.6081226468086243]\n\nEpoch 23/30\nTrain Loss1: 0.04173228442668915\nTrain Loss2: 0.05699179172515869\nTrain Loss AU: 0.5352723121643066\nTrain Loss EU: 0.5823578834533691\nTrain DSC: [0.9035114049911499]\nValidation Loss1: 0.1638346290588379\nValidation Loss2: 0.1780843162536621\nValidation Loss AU: 0.6539584350585937\nValidation Loss EU: 0.7899723052978516\nValidation DSC: [0.632048487663269]\n\nEpoch 24/30\nTrain Loss1: 0.045500347018241884\nTrain Loss2: 0.05428221821784973\nTrain Loss AU: 0.5377317905426026\nTrain Loss EU: 0.5822039604187011\nTrain DSC: [0.8939744830131531]\nValidation Loss1: 0.13106688499450683\nValidation Loss2: 0.16778432846069335\nValidation Loss AU: 0.6552346801757812\nValidation Loss EU: 0.7904546356201172\nValidation DSC: [0.7001985907554626]\n\nEpoch 25/30\nTrain Loss1: 0.042112356424331664\nTrain Loss2: 0.05538663864135742\nTrain Loss AU: 0.5431187629699707\nTrain Loss EU: 0.5853022575378418\nTrain DSC: [0.901760458946228]\nValidation Loss1: 0.14996695518493652\nValidation Loss2: 0.1652810478210449\nValidation Loss AU: 0.6487972259521484\nValidation Loss EU: 0.7799491119384766\nValidation DSC: [0.6639095544815063]\n\nEpoch 26/30\nTrain Loss1: 0.040960609912872314\nTrain Loss2: 0.04230672419071198\nTrain Loss AU: 0.5330888271331787\nTrain Loss EU: 0.5791060447692871\nTrain DSC: [0.9043475985527039]\nValidation Loss1: 0.1795915985107422\nValidation Loss2: 0.18739023208618164\nValidation Loss AU: 0.6725517272949219\nValidation Loss EU: 0.8203932189941406\nValidation DSC: [0.6002591848373413]\n\nEpoch 27/30\nTrain Loss1: 0.04161452353000641\nTrain Loss2: 0.05986650586128235\nTrain Loss AU: 0.5322558403015136\nTrain Loss EU: 0.5757487773895263\nTrain DSC: [0.9037628173828125]\nValidation Loss1: 0.1326371479034424\nValidation Loss2: 0.15490241050720216\nValidation Loss AU: 0.6370452499389648\nValidation Loss EU: 0.760517578125\nValidation DSC: [0.6948988437652588]\n\nEpoch 28/30\nTrain Loss1: 0.03713175058364868\nTrain Loss2: 0.05944564938545227\nTrain Loss AU: 0.5362232208251954\nTrain Loss EU: 0.5803344249725342\nTrain DSC: [0.914379894733429]\nValidation Loss1: 0.13401104927062987\nValidation Loss2: 0.1717684745788574\nValidation Loss AU: 0.6481034851074219\nValidation Loss EU: 0.7781792449951171\nValidation DSC: [0.6935621500015259]\n\nEpoch 29/30\nTrain Loss1: 0.03546000421047211\nTrain Loss2: 0.05135526061058045\nTrain Loss AU: 0.529969596862793\nTrain Loss EU: 0.5710629463195801\nTrain DSC: [0.9166918992996216]\nValidation Loss1: 0.14796009063720703\nValidation Loss2: 0.16652938842773438\nValidation Loss AU: 0.6428355407714844\nValidation Loss EU: 0.7707662200927734\nValidation DSC: [0.6659411787986755]\n\nEpoch 30/30\nTrain Loss1: 0.034911158680915835\nTrain Loss2: 0.051438772678375246\nTrain Loss AU: 0.5328354358673095\nTrain Loss EU: 0.5724130153656006\nTrain DSC: [0.919040858745575]\nValidation Loss1: 0.1950349235534668\nValidation Loss2: 0.18726751327514649\nValidation Loss AU: 0.677798843383789\nValidation Loss EU: 0.8332210540771484\nValidation DSC: [0.5696536302566528]\n\nEpoch 1/30\nTrain Loss1: 0.10406259298324586\nTrain Loss2: 0.10872342586517333\nTrain Loss AU: 0.6371302127838134\nTrain Loss EU: 0.7709988117218017\nTrain DSC: [0.7827569246292114]\nValidation Loss1: 0.24922775268554687\nValidation Loss2: 0.22557346343994142\nValidation Loss AU: 0.7075250244140625\nValidation Loss EU: 0.8873835754394531\nValidation DSC: [0.4446152448654175]\n\nEpoch 2/30\nTrain Loss1: 0.10045536756515502\nTrain Loss2: 0.10853122472763062\nTrain Loss AU: 0.5921168327331543\nTrain Loss EU: 0.6890537738800049\nTrain DSC: [0.7918199300765991]\nValidation Loss1: 0.155272741317749\nValidation Loss2: 0.19884647369384767\nValidation Loss AU: 0.6457311248779297\nValidation Loss EU: 0.7784158325195313\nValidation DSC: [0.6688178777694702]\n\nEpoch 3/30\nTrain Loss1: 0.08499322533607483\nTrain Loss2: 0.08506609201431274\nTrain Loss AU: 0.5696088314056397\nTrain Loss EU: 0.6435165405273438\nTrain DSC: [0.8252347707748413]\nValidation Loss1: 0.22543899536132814\nValidation Loss2: 0.21407251358032225\nValidation Loss AU: 0.6939530181884765\nValidation Loss EU: 0.8639542388916016\nValidation DSC: [0.5069726705551147]\n\nEpoch 4/30\nTrain Loss1: 0.08412374258041382\nTrain Loss2: 0.08764107227325439\nTrain Loss AU: 0.5898422241210938\nTrain Loss EU: 0.6745565414428711\nTrain DSC: [0.8199992179870605]\nValidation Loss1: 0.16176666259765626\nValidation Loss2: 0.20604236602783202\nValidation Loss AU: 0.6489671325683594\nValidation Loss EU: 0.7844222259521484\nValidation DSC: [0.640847384929657]\n\nEpoch 5/30\nTrain Loss1: 0.09985635280609131\nTrain Loss2: 0.10935308933258056\nTrain Loss AU: 0.5705644607543945\nTrain Loss EU: 0.6473424434661865\nTrain DSC: [0.7780465483665466]\nValidation Loss1: 0.26821395874023435\nValidation Loss2: 0.2744572639465332\nValidation Loss AU: 0.7352486419677734\nValidation Loss EU: 0.9332099151611328\nValidation DSC: [0.40160632133483887]\n\nEpoch 6/30\nTrain Loss1: 0.09228739738464356\nTrain Loss2: 0.12408912181854248\nTrain Loss AU: 0.5837700843811036\nTrain Loss EU: 0.6673136234283448\nTrain DSC: [0.7962441444396973]\nValidation Loss1: 0.13336960792541505\nValidation Loss2: 0.17379701614379883\nValidation Loss AU: 0.6337611389160156\nValidation Loss EU: 0.7551400756835938\nValidation DSC: [0.7035606503486633]\n\nEpoch 7/30\nTrain Loss1: 0.08409340977668762\nTrain Loss2: 0.09507733583450317\nTrain Loss AU: 0.5715127944946289\nTrain Loss EU: 0.6402746200561523\nTrain DSC: [0.8140448331832886]\nValidation Loss1: 0.1452203845977783\nValidation Loss2: 0.19587547302246094\nValidation Loss AU: 0.6421507263183593\nValidation Loss EU: 0.7648110961914063\nValidation DSC: [0.6759853959083557]\n\nEpoch 8/30\nTrain Loss1: 0.07663835287094116\nTrain Loss2: 0.09057779908180237\nTrain Loss AU: 0.552428150177002\nTrain Loss EU: 0.6154497146606446\nTrain DSC: [0.8299877047538757]\nValidation Loss1: 0.1777387046813965\nValidation Loss2: 0.19425212860107421\nValidation Loss AU: 0.652686538696289\nValidation Loss EU: 0.7812314605712891\nValidation DSC: [0.6068924069404602]\n\nEpoch 9/30\nTrain Loss1: 0.07514574527740478\nTrain Loss2: 0.07653034925460815\nTrain Loss AU: 0.573681640625\nTrain Loss EU: 0.645170259475708\nTrain DSC: [0.8334105610847473]\nValidation Loss1: 0.18326650619506835\nValidation Loss2: 0.18945253372192383\nValidation Loss AU: 0.6639761352539062\nValidation Loss EU: 0.804679183959961\nValidation DSC: [0.5868569612503052]\n\nEpoch 10/30\nTrain Loss1: 0.0778010606765747\nTrain Loss2: 0.07354609370231628\nTrain Loss AU: 0.5323076248168945\nTrain Loss EU: 0.5763644695281982\nTrain DSC: [0.8220481872558594]\nValidation Loss1: 0.14872345924377442\nValidation Loss2: 0.2034686851501465\nValidation Loss AU: 0.6396270751953125\nValidation Loss EU: 0.7622903442382812\nValidation DSC: [0.6615696549415588]\n\nEpoch 11/30\nTrain Loss1: 0.0710829257965088\nTrain Loss2: 0.08372637033462524\nTrain Loss AU: 0.5310751438140869\nTrain Loss EU: 0.5649037837982178\nTrain DSC: [0.8389986157417297]\nValidation Loss1: 0.13724565505981445\nValidation Loss2: 0.17551445007324218\nValidation Loss AU: 0.6381101608276367\nValidation Loss EU: 0.7556584167480469\nValidation DSC: [0.6916801929473877]\n\nEpoch 12/30\nTrain Loss1: 0.06820259094238282\nTrain Loss2: 0.06547775268554687\nTrain Loss AU: 0.5279989242553711\nTrain Loss EU: 0.5609943389892578\nTrain DSC: [0.8463818430900574]\nValidation Loss1: 0.20428003311157228\nValidation Loss2: 0.19165214538574218\nValidation Loss AU: 0.6806745910644532\nValidation Loss EU: 0.8362554168701172\nValidation DSC: [0.5504993200302124]\n\nEpoch 13/30\nTrain Loss1: 0.06837106347084046\nTrain Loss2: 0.06280087232589722\nTrain Loss AU: 0.536113691329956\nTrain Loss EU: 0.575199556350708\nTrain DSC: [0.8473272323608398]\nValidation Loss1: 0.12818930625915528\nValidation Loss2: 0.16543827056884766\nValidation Loss AU: 0.6330622482299805\nValidation Loss EU: 0.754671630859375\nValidation DSC: [0.7088977694511414]\n\nEpoch 14/30\nTrain Loss1: 0.06693155169487\nTrain Loss2: 0.07653160691261292\nTrain Loss AU: 0.5213381767272949\nTrain Loss EU: 0.5600666999816895\nTrain DSC: [0.846258819103241]\nValidation Loss1: 0.1362849712371826\nValidation Loss2: 0.17169267654418946\nValidation Loss AU: 0.6374584197998047\nValidation Loss EU: 0.7577128601074219\nValidation DSC: [0.6908419132232666]\n\nEpoch 15/30\nTrain Loss1: 0.06848081946372986\nTrain Loss2: 0.07279586791992188\nTrain Loss AU: 0.5125608921051026\nTrain Loss EU: 0.5395240783691406\nTrain DSC: [0.8418170809745789]\nValidation Loss1: 0.14331344604492188\nValidation Loss2: 0.1822866439819336\nValidation Loss AU: 0.6285496520996093\nValidation Loss EU: 0.7422878265380859\nValidation DSC: [0.6778607964515686]\n\nEpoch 16/30\nTrain Loss1: 0.06881066560745239\nTrain Loss2: 0.09008617997169495\nTrain Loss AU: 0.5372144699096679\nTrain Loss EU: 0.5800154685974122\nTrain DSC: [0.8433736562728882]\nValidation Loss1: 0.15184678077697755\nValidation Loss2: 0.18315889358520507\nValidation Loss AU: 0.6438411712646485\nValidation Loss EU: 0.7727098846435547\nValidation DSC: [0.6567432880401611]\n\nEpoch 17/30\nTrain Loss1: 0.06725188493728637\nTrain Loss2: 0.07828621864318848\nTrain Loss AU: 0.5243334770202637\nTrain Loss EU: 0.5550912857055664\nTrain DSC: [0.8443781137466431]\nValidation Loss1: 0.17504671096801758\nValidation Loss2: 0.1957234573364258\nValidation Loss AU: 0.6583055114746094\nValidation Loss EU: 0.7871578979492188\nValidation DSC: [0.6087380647659302]\n\nEpoch 18/30\nTrain Loss1: 0.07254781126976013\nTrain Loss2: 0.06789287328720092\nTrain Loss AU: 0.5257338523864746\nTrain Loss EU: 0.5576460838317872\nTrain DSC: [0.8342846035957336]\nValidation Loss1: 0.14930835723876953\nValidation Loss2: 0.187470703125\nValidation Loss AU: 0.6311905288696289\nValidation Loss EU: 0.7439778900146484\nValidation DSC: [0.6634281873703003]\n\nEpoch 19/30\nTrain Loss1: 0.06896620988845825\nTrain Loss2: 0.09724656343460084\nTrain Loss AU: 0.51647047996521\nTrain Loss EU: 0.546499490737915\nTrain DSC: [0.8401870727539062]\nValidation Loss1: 0.13963583946228028\nValidation Loss2: 0.1647465705871582\nValidation Loss AU: 0.6360261154174804\nValidation Loss EU: 0.7504439544677735\nValidation DSC: [0.6829938292503357]\n\nEpoch 20/30\nTrain Loss1: 0.061682939529418945\nTrain Loss2: 0.07272992730140686\nTrain Loss AU: 0.5129239082336425\nTrain Loss EU: 0.5347477912902832\nTrain DSC: [0.8586858510971069]\nValidation Loss1: 0.15097009658813476\nValidation Loss2: 0.1835034942626953\nValidation Loss AU: 0.6417286682128907\nValidation Loss EU: 0.7679351806640625\nValidation DSC: [0.6596512794494629]\n\nEpoch 21/30\nTrain Loss1: 0.06598707437515258\nTrain Loss2: 0.07981802821159363\nTrain Loss AU: 0.5198004245758057\nTrain Loss EU: 0.5513023376464844\nTrain DSC: [0.8463616371154785]\nValidation Loss1: 0.14179075241088868\nValidation Loss2: 0.17703269958496093\nValidation Loss AU: 0.6289578628540039\nValidation Loss EU: 0.7435961151123047\nValidation DSC: [0.6803375482559204]\n\nEpoch 22/30\nTrain Loss1: 0.06141574382781982\nTrain Loss2: 0.07515243887901306\nTrain Loss AU: 0.5063752651214599\nTrain Loss EU: 0.5279876232147217\nTrain DSC: [0.8572951555252075]\nValidation Loss1: 0.15283985137939454\nValidation Loss2: 0.17676176071166994\nValidation Loss AU: 0.6387421035766602\nValidation Loss EU: 0.7610064697265625\nValidation DSC: [0.6592605710029602]\n\nEpoch 23/30\nTrain Loss1: 0.060063475370407106\nTrain Loss2: 0.07581827640533448\nTrain Loss AU: 0.49021615982055666\nTrain Loss EU: 0.49129257202148435\nTrain DSC: [0.8613418340682983]\nValidation Loss1: 0.14449165344238282\nValidation Loss2: 0.1797579574584961\nValidation Loss AU: 0.6395249557495117\nValidation Loss EU: 0.7631989288330078\nValidation DSC: [0.6729316115379333]\n\nEpoch 24/30\nTrain Loss1: 0.060443222522735596\nTrain Loss2: 0.07822081446647644\nTrain Loss AU: 0.4820125579833984\nTrain Loss EU: 0.48320460319519043\nTrain DSC: [0.8607246279716492]\nValidation Loss1: 0.14806584358215333\nValidation Loss2: 0.1655047607421875\nValidation Loss AU: 0.6316933059692382\nValidation Loss EU: 0.7542299652099609\nValidation DSC: [0.6666763424873352]\n\nEpoch 25/30\nTrain Loss1: 0.05950108766555786\nTrain Loss2: 0.06730632185935974\nTrain Loss AU: 0.49942569732666015\nTrain Loss EU: 0.5069848537445069\nTrain DSC: [0.8615707159042358]\nValidation Loss1: 0.13302226066589357\nValidation Loss2: 0.16218976974487304\nValidation Loss AU: 0.6331312179565429\nValidation Loss EU: 0.7497447204589843\nValidation DSC: [0.6983144283294678]\n\nEpoch 26/30\nTrain Loss1: 0.05707076787948608\nTrain Loss2: 0.07178545594215394\nTrain Loss AU: 0.49159822463989256\nTrain Loss EU: 0.5018909454345704\nTrain DSC: [0.8661044836044312]\nValidation Loss1: 0.16251789093017577\nValidation Loss2: 0.17873544692993165\nValidation Loss AU: 0.6497054290771485\nValidation Loss EU: 0.7819126129150391\nValidation DSC: [0.6361653208732605]\n\nEpoch 27/30\nTrain Loss1: 0.05609215497970581\nTrain Loss2: 0.06386241912841797\nTrain Loss AU: 0.48758516311645506\nTrain Loss EU: 0.5010841846466064\nTrain DSC: [0.8696529269218445]\nValidation Loss1: 0.15438616752624512\nValidation Loss2: 0.1946602249145508\nValidation Loss AU: 0.6403588104248047\nValidation Loss EU: 0.7618568420410157\nValidation DSC: [0.6523510813713074]\n\nEpoch 28/30\nTrain Loss1: 0.05839066505432129\nTrain Loss2: 0.09140282273292541\nTrain Loss AU: 0.4947462558746338\nTrain Loss EU: 0.49930782318115235\nTrain DSC: [0.8633905649185181]\nValidation Loss1: 0.13698091506958007\nValidation Loss2: 0.17243526458740235\nValidation Loss AU: 0.6341216278076172\nValidation Loss EU: 0.7543122100830079\nValidation DSC: [0.6888958811759949]\n\nEpoch 29/30\nTrain Loss1: 0.05376079082489014\nTrain Loss2: 0.07786061763763427\nTrain Loss AU: 0.4934929370880127\nTrain Loss EU: 0.506734561920166\nTrain DSC: [0.8736525774002075]\nValidation Loss1: 0.1719679069519043\nValidation Loss2: 0.1897545051574707\nValidation Loss AU: 0.6582276153564454\nValidation Loss EU: 0.7911334991455078\nValidation DSC: [0.6147368550300598]\n\nEpoch 30/30\nTrain Loss1: 0.059339845180511476\nTrain Loss2: 0.07724825143814087\nTrain Loss AU: 0.5057664394378663\nTrain Loss EU: 0.5281437873840332\nTrain DSC: [0.8606976270675659]\nValidation Loss1: 0.14995737075805665\nValidation Loss2: 0.16551347732543945\nValidation Loss AU: 0.6299236297607422\nValidation Loss EU: 0.7448786163330078\nValidation DSC: [0.6633695960044861]\n\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675237470872
        }
      },
      "id": "c7e59eb8-6ede-4257-939a-85d49a3377c4"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": false,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "shapeworks"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "shapeworks",
      "language": "python",
      "display_name": "Python (shapeworks)"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}