{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import gc\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import scipy.ndimage as ndimage\n",
        "import nrrd\n",
        "import torchio as tio\n",
        "import monai\n",
        "import nibabel as nib\n",
        "from collections import OrderedDict, defaultdict"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1676995987391
        },
        "id": "8246ca62",
        "scrolled": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "id": "8246ca62"
    },
    {
      "cell_type": "code",
      "source": [
        "city = 'Ellipsoids_FP'\n",
        "IMAGE_DIR = f'../dataset/{city}/images'\n",
        "IMAGE_ARTI_DIR = f'../dataset/{city}/images_arti'\n",
        "MASK_DIR = f'../dataset/{city}/segmentations'\n",
        "\n",
        "ed_dir = '../dataset/Ellipsoids/models'\n",
        "encoder_path = f'{ed_dir}/best_encoder.torch'\n",
        "decoder_path = f'{ed_dir}/best_decoder.torch'\n",
        "\n",
        "num_classes = 2\n",
        "TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 50, 10, 21\n",
        "TOTAL_SIZE = TRAIN_SIZE + VAL_SIZE + TEST_SIZE\n",
        "\n",
        "output_dir = f'../results/{city}_ellp_ed/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1676995988527
        }
      },
      "id": "fe9e2ac9"
    },
    {
      "cell_type": "code",
      "source": [
        "def AE():\n",
        "    autoencoder = monai.networks.nets.AutoEncoder(\n",
        "        spatial_dims=3, in_channels=1, out_channels=1,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        channels=[channel*1 for channel in (1, 2, 4, 8, 16)],\n",
        "        strides=(1, 2, 2, 2, 2),\n",
        "    )\n",
        "    return autoencoder\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv = AE().encode\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1, 1024),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.PReLU(),\n",
        "        )\n",
        "        self.deconv = AE().decode\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = torch.reshape(x, (1, 16, 4, 4, 4))\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n",
        "\n",
        "class StraightThroughEstimator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StraightThroughEstimator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = STEFunction.apply(x)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.segmentation = monai.networks.nets.UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            channels=(32, 64, 128, 256, 512),\n",
        "            strides=(2, 2, 2, 2),\n",
        "            norm=monai.networks.layers.Norm.BATCH,\n",
        "        )\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.ste = StraightThroughEstimator()\n",
        "\n",
        "        self.encoder, self.decoder = Encoder(), Decoder()\n",
        "        for coder, coder_path in zip([self.encoder, self.decoder], [encoder_path, decoder_path]):\n",
        "            coder.load_state_dict(torch.load(coder_path))\n",
        "            for param in coder.parameters():\n",
        "                param.requires_grad = False\n",
        "            coder.eval()\n",
        "\n",
        "    def forward(self, image):\n",
        "        prob = self.softmax(self.segmentation(image))\n",
        "        binary_mask = self.ste(prob[:, 1:2, :, :, :] - 0.5)\n",
        "        shape = self.encoder(binary_mask)\n",
        "        shape = torch.clamp(shape, min=10, max=30)\n",
        "        recon = self.decoder(shape)\n",
        "        return prob, binary_mask, shape, recon"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676995988715
        }
      },
      "id": "08c41641-3801-405d-809e-5299cd7ef1df"
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "random_state = np.random.RandomState(seed=seed)\n",
        "perm = random_state.permutation(TOTAL_SIZE)\n",
        "perm = {\n",
        "    'train': perm[:TRAIN_SIZE],\n",
        "    'validation': perm[TRAIN_SIZE:TRAIN_SIZE+VAL_SIZE],\n",
        "    'test': perm[-TEST_SIZE:],\n",
        "}\n",
        "\n",
        "def get_subjects(mode):\n",
        "    subjects = []\n",
        "    image_paths = [sorted(glob(f'{IMAGE_DIR}/*.nrrd'))[i] for i in perm[mode]]\n",
        "    for image_path in tqdm(image_paths):\n",
        "        filename = image_path.split('/')[-1]\n",
        "        mask_path = f'{MASK_DIR}/{filename}'\n",
        "        image_arti_path = f'{IMAGE_ARTI_DIR}/{filename}'\n",
        "        subject = tio.Subject(\n",
        "            t1=tio.ScalarImage(image_arti_path),#image_path if mode == 'train' else image_arti_path),\n",
        "            label=tio.LabelMap(mask_path),\n",
        "            radius=torch.Tensor([float(filename.split('_')[-1][:5])]),\n",
        "        )\n",
        "        subjects.append(subject)\n",
        "    return subjects\n",
        "\n",
        "def get_dataloader(transform):\n",
        "    dataloader = dict()\n",
        "    for mode in ['train', 'validation', 'test']:\n",
        "        dataloader[mode] = torch.utils.data.DataLoader(\n",
        "            tio.SubjectsDataset(\n",
        "                subjects[mode], \n",
        "                transform=transform\n",
        "            ),\n",
        "            batch_size=1, \n",
        "            num_workers=os.cpu_count(),\n",
        "            shuffle=False,\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "subjects = dict()\n",
        "for mode in ['train', 'validation', 'test']:\n",
        "    subjects[mode] = get_subjects(mode)\n",
        "\n",
        "signal = tio.Compose([ \n",
        "    tio.RescaleIntensity(percentiles=(0.1, 99.9), out_min_max=(0, 1)),\n",
        "])\n",
        "\n",
        "transform = tio.Compose([\n",
        "    signal,\n",
        "])\n",
        "\n",
        "dataloader = get_dataloader(transform)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 50/50 [00:01<00:00, 36.20it/s]\n100%|██████████| 10/10 [00:00<00:00, 36.46it/s]\n100%|██████████| 21/21 [00:00<00:00, 36.67it/s]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1676995992464
        },
        "id": "iwKH3_Dd1ehr"
      },
      "id": "iwKH3_Dd1ehr"
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "    def __init__(self):\n",
        "        self.metrics = defaultdict(list)\n",
        "        self.names = ['loss', 'loss_segm', 'loss_shape', 'loss_recon']\n",
        "    def log(self, mode, epoch, values):\n",
        "        for name, value in zip(self.names, values):\n",
        "            self.metrics[(mode, epoch, name)].append(value.item())\n",
        "    def show(self, mode, epoch):\n",
        "        print()\n",
        "        for name in self.names:\n",
        "            mean = np.mean(self.metrics[(mode, epoch, name)])\n",
        "            print(f'{mode} {name}: {mean}')\n",
        "\n",
        "def test(lambdas, save):\n",
        "    mode = 'test'\n",
        "    model.load_state_dict(torch.load(f'{output_dir}/best_model.torch'))\n",
        "    model.eval()\n",
        "\n",
        "    loss_dice_segm = monai.losses.DiceLoss(squared_pred=True).to(DEVICE)\n",
        "    loss_mae_shape = torch.nn.L1Loss().to(DEVICE)\n",
        "    loss_dice_recon = monai.losses.DiceLoss(sigmoid=True, squared_pred=True).to(DEVICE)\n",
        "    \n",
        "    metric = monai.metrics.DiceMetric(include_background=False, reduction='mean_batch')\n",
        "    metrics = Metrics()\n",
        "\n",
        "    for i, subject in enumerate(dataloader['test']):\n",
        "        image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "        label = subject['label'][tio.DATA].to(DEVICE)\n",
        "        one_hot_label = monai.networks.utils.one_hot(label, num_classes=num_classes, dim=1).to(DEVICE)\n",
        "        radius = subject['radius'].to(DEVICE)\n",
        "\n",
        "        prob, binary_mask, shape, recon = model(image)\n",
        "        loss_segm = loss_dice_segm(prob, one_hot_label)\n",
        "        loss_shape = loss_mae_shape(shape, radius)\n",
        "        # loss_recon = loss_dice_recon(recon, one_hot_label[:, 1:2, :, :, :])\n",
        "        loss_recon = loss_dice_recon(recon, binary_mask)\n",
        "\n",
        "        loss = lambdas[0] * loss_segm + lambdas[1] * loss_shape + lambdas[2] * loss_recon\n",
        "                \n",
        "        metric(binary_mask, one_hot_label)\n",
        "        metrics.log(mode, 1, [loss, loss_segm, loss_shape, loss_recon])\n",
        "        \n",
        "        if save:\n",
        "            dest = f'{output_dir}{mode}_sample{i}.nrrd'\n",
        "            nrrd.write(dest, binary_mask.detach().cpu().numpy()[0, 0])\n",
        "\n",
        "    metrics.show(mode, 1)\n",
        "    mean_dsc = metric.aggregate().tolist()[0]\n",
        "    metric.reset()\n",
        "    print(f'{mode} DSC: {mean_dsc}')\n",
        "    if save:\n",
        "        !rm file.zip\n",
        "        !zip -r file.zip $output_dir\n",
        "\n",
        "def train(model, lambdas, n_epochs, dataloader, learning_rate):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
        "\n",
        "    loss_dice_segm = monai.losses.DiceLoss(squared_pred=True).to(DEVICE)\n",
        "    loss_mae_shape = torch.nn.L1Loss().to(DEVICE)\n",
        "    loss_dice_recon = monai.losses.DiceLoss(sigmoid=True, squared_pred=True).to(DEVICE)\n",
        "    \n",
        "    metric = monai.metrics.DiceMetric(include_background=False, reduction='mean_batch')\n",
        "    metrics = Metrics()\n",
        "    best_val_dsc = 0\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        print(f'\\nEpoch {epoch}/{n_epochs}')\n",
        "        for mode in ['train', 'validation']:\n",
        "            if mode == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            for subject in dataloader[mode]:\n",
        "                image = subject['t1'][tio.DATA].to(DEVICE)\n",
        "                label = subject['label'][tio.DATA].to(DEVICE)\n",
        "                one_hot_label = monai.networks.utils.one_hot(label, num_classes=num_classes, dim=1).to(DEVICE)\n",
        "                radius = subject['radius'].to(DEVICE)\n",
        "\n",
        "                prob, binary_mask, shape, recon = model(image)\n",
        "                loss_segm = loss_dice_segm(prob, one_hot_label)\n",
        "                loss_shape = loss_mae_shape(shape, radius)\n",
        "                # loss_recon = loss_dice_recon(recon, one_hot_label[:, 1:2, :, :, :])\n",
        "                loss_recon = loss_dice_recon(recon, binary_mask)\n",
        "\n",
        "                loss = lambdas[0] * loss_segm + lambdas[1] * loss_shape + lambdas[2] * loss_recon\n",
        "\n",
        "                if mode == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                \n",
        "                metric(binary_mask, one_hot_label)\n",
        "                metrics.log(mode, epoch, [loss, loss_segm, loss_shape, loss_recon])\n",
        "\n",
        "            metrics.show(mode, epoch)\n",
        "            mean_dsc = metric.aggregate().tolist()[0]\n",
        "            metric.reset()\n",
        "            print(f'{mode} DSC: {mean_dsc}')\n",
        "            \n",
        "        scheduler.step()\n",
        "        if mean_dsc > best_val_dsc:\n",
        "            best_val_dsc = mean_dsc\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), f'{output_dir}/best_model.torch')\n",
        "    \n",
        "    print(f'Best model saved after epoch {best_epoch} (val dsc = {best_val_dsc}).')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676995992630
        }
      },
      "id": "32b9f1a8-b3e3-4f8a-9425-d55fd64735c0"
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676949139148
        }
      },
      "id": "e3c05af8-bbed-4095-b7dc-244cbee1b66b"
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas = (1, 0, 0)\n",
        "model = Model().to(DEVICE)\n",
        "train(model=model, lambdas=lambdas, n_epochs=30, dataloader=dataloader, learning_rate=1e-4)\n",
        "test(lambdas=lambdas, save=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nEpoch 1/30\n\ntrain loss: 0.4916696602106094\ntrain loss_segm: 0.4916696602106094\ntrain loss_shape: 6.958824768066406\ntrain loss_recon: 0.8825270140171051\ntrain DSC: 0.14639776945114136\n\nvalidation loss: 0.45185542702674864\nvalidation loss_segm: 0.45185542702674864\nvalidation loss_shape: 3.964399528503418\nvalidation loss_recon: 0.8222893357276917\nvalidation DSC: 0.195532888174057\n\nEpoch 2/30\n\ntrain loss: 0.3885744571685791\ntrain loss_segm: 0.3885744571685791\ntrain loss_shape: 4.396340789794922\ntrain loss_recon: 0.6954705333709716\ntrain DSC: 0.33226895332336426\n\nvalidation loss: 0.35789439976215365\nvalidation loss_segm: 0.35789439976215365\nvalidation loss_shape: 3.2054320335388184\nvalidation loss_recon: 0.5427184939384461\nvalidation DSC: 0.4494542181491852\n\nEpoch 3/30\n\ntrain loss: 0.29368232369422914\ntrain loss_segm: 0.29368232369422914\ntrain loss_shape: 2.259503574371338\ntrain loss_recon: 0.2725664293766022\ntrain DSC: 0.7043095231056213\n\nvalidation loss: 0.26661414802074435\nvalidation loss_segm: 0.26661414802074435\nvalidation loss_shape: 1.765915298461914\nvalidation loss_recon: 0.12234286069869996\nvalidation DSC: 0.8471899032592773\n\nEpoch 4/30\n\ntrain loss: 0.20562773883342744\ntrain loss_segm: 0.20562773883342744\ntrain loss_shape: 1.5380060005187988\ntrain loss_recon: 0.055152255296707156\ntrain DSC: 0.9184229373931885\n\nvalidation loss: 0.18761729896068574\nvalidation loss_segm: 0.18761729896068574\nvalidation loss_shape: 1.4773021697998048\nvalidation loss_recon: 0.0364037275314331\nvalidation DSC: 0.9404767751693726\n\nEpoch 5/30\n\ntrain loss: 0.13822471261024474\ntrain loss_segm: 0.13822471261024474\ntrain loss_shape: 1.0468422698974609\ntrain loss_recon: 0.02784930944442749\ntrain DSC: 0.9577364325523376\n\nvalidation loss: 0.12870106995105743\nvalidation loss_segm: 0.12870106995105743\nvalidation loss_shape: 1.1914423942565917\nvalidation loss_recon: 0.02963194251060486\nvalidation DSC: 0.9515312314033508\n\nEpoch 6/30\n\ntrain loss: 0.09475093185901642\ntrain loss_segm: 0.09475093185901642\ntrain loss_shape: 0.8726410293579101\ntrain loss_recon: 0.023486206531524657\ntrain DSC: 0.9638017416000366\n\nvalidation loss: 0.08948353528976441\nvalidation loss_segm: 0.08948353528976441\nvalidation loss_shape: 0.5723235130310058\nvalidation loss_recon: 0.021857941150665285\nvalidation DSC: 0.9694150686264038\n\nEpoch 7/30\n\ntrain loss: 0.06627810001373291\ntrain loss_segm: 0.06627810001373291\ntrain loss_shape: 0.7481556892395019\ntrain loss_recon: 0.019394946098327637\ntrain DSC: 0.9714413285255432\n\nvalidation loss: 0.06415339410305024\nvalidation loss_segm: 0.06415339410305024\nvalidation loss_shape: 0.3999655723571777\nvalidation loss_recon: 0.019064944982528687\nvalidation DSC: 0.9738078117370605\n\nEpoch 8/30\n\ntrain loss: 0.048764078617095946\ntrain loss_segm: 0.048764078617095946\ntrain loss_shape: 0.5561566352844238\ntrain loss_recon: 0.017066065073013306\ntrain DSC: 0.9765425324440002\n\nvalidation loss: 0.053218218684196475\nvalidation loss_segm: 0.053218218684196475\nvalidation loss_shape: 0.8803631782531738\nvalidation loss_recon: 0.02149394154548645\nvalidation DSC: 0.9660100936889648\n\nEpoch 9/30\n\ntrain loss: 0.037938098907470706\ntrain loss_segm: 0.037938098907470706\ntrain loss_shape: 0.43585886001586915\ntrain loss_recon: 0.015966516733169556\ntrain DSC: 0.9786451458930969\n\nvalidation loss: 0.04736558198928833\nvalidation loss_segm: 0.04736558198928833\nvalidation loss_shape: 1.3345376968383789\nvalidation loss_recon: 0.023200637102127074\nvalidation DSC: 0.9582117199897766\n\nEpoch 10/30\n\ntrain loss: 0.032272654175758364\ntrain loss_segm: 0.032272654175758364\ntrain loss_shape: 0.6384701728820801\ntrain loss_recon: 0.01701031804084778\ntrain DSC: 0.9754127264022827\n\nvalidation loss: 0.032543417811393735\nvalidation loss_segm: 0.032543417811393735\nvalidation loss_shape: 0.5398080825805665\nvalidation loss_recon: 0.01670491099357605\nvalidation DSC: 0.9768560528755188\n\nEpoch 11/30\n\ntrain loss: 0.02744297742843628\ntrain loss_segm: 0.02744297742843628\ntrain loss_shape: 0.6121996116638183\ntrain loss_recon: 0.017267086505889893\ntrain DSC: 0.9756646752357483\n\nvalidation loss: 0.027532866597175597\nvalidation loss_segm: 0.027532866597175597\nvalidation loss_shape: 0.40322303771972656\nvalidation loss_recon: 0.015654820203781127\nvalidation DSC: 0.9771226644515991\n\nEpoch 12/30\n\ntrain loss: 0.022424001693725586\ntrain loss_segm: 0.022424001693725586\ntrain loss_shape: 0.48177295684814453\ntrain loss_recon: 0.014927058219909669\ntrain DSC: 0.9808425307273865\n\nvalidation loss: 0.023966902494430543\nvalidation loss_segm: 0.023966902494430543\nvalidation loss_shape: 0.37456722259521485\nvalidation loss_recon: 0.016040986776351927\nvalidation DSC: 0.9771308898925781\n\nEpoch 13/30\n\ntrain loss: 0.019845338463783266\ntrain loss_segm: 0.019845338463783266\ntrain loss_shape: 0.511910343170166\ntrain loss_recon: 0.013931289911270142\ntrain DSC: 0.9810211062431335\n\nvalidation loss: 0.021512356400489808\nvalidation loss_segm: 0.021512356400489808\nvalidation loss_shape: 0.5176103591918946\nvalidation loss_recon: 0.01375071406364441\nvalidation DSC: 0.9784770011901855\n\nEpoch 14/30\n\ntrain loss: 0.01715803027153015\ntrain loss_segm: 0.01715803027153015\ntrain loss_shape: 0.4040930557250977\ntrain loss_recon: 0.013723783493041992\ntrain DSC: 0.9835728406906128\n\nvalidation loss: 0.019956108927726746\nvalidation loss_segm: 0.019956108927726746\nvalidation loss_shape: 0.6621658325195312\nvalidation loss_recon: 0.013952147960662842\nvalidation DSC: 0.976915717124939\n\nEpoch 15/30\n\ntrain loss: 0.014875779151916504\ntrain loss_segm: 0.014875779151916504\ntrain loss_shape: 0.30690507888793944\ntrain loss_recon: 0.012562323808670044\ntrain DSC: 0.9863864183425903\n\nvalidation loss: 0.01926509439945221\nvalidation loss_segm: 0.01926509439945221\nvalidation loss_shape: 0.6840022087097168\nvalidation loss_recon: 0.015018963813781738\nvalidation DSC: 0.9745771288871765\n\nEpoch 16/30\n\ntrain loss: 0.013257882595062255\ntrain loss_segm: 0.013257882595062255\ntrain loss_shape: 0.24985866546630858\ntrain loss_recon: 0.011760748624801635\ntrain DSC: 0.9881008267402649\n\nvalidation loss: 0.017509925365447997\nvalidation loss_segm: 0.017509925365447997\nvalidation loss_shape: 0.6033056259155274\nvalidation loss_recon: 0.014996421337127686\nvalidation DSC: 0.9759410619735718\n\nEpoch 17/30\n\ntrain loss: 0.012971228957176208\ntrain loss_segm: 0.012971228957176208\ntrain loss_shape: 0.3963775062561035\ntrain loss_recon: 0.012332056760787963\ntrain DSC: 0.9856739640235901\n\nvalidation loss: 0.015507671236991882\nvalidation loss_segm: 0.015507671236991882\nvalidation loss_shape: 0.41993007659912107\nvalidation loss_recon: 0.016561400890350342\nvalidation DSC: 0.9779747128486633\n\nEpoch 18/30\n\ntrain loss: 0.012374315857887268\ntrain loss_segm: 0.012374315857887268\ntrain loss_shape: 0.4036379241943359\ntrain loss_recon: 0.013101042509078979\ntrain DSC: 0.9848181009292603\n\nvalidation loss: 0.014564809203147889\nvalidation loss_segm: 0.014564809203147889\nvalidation loss_shape: 0.5605401039123535\nvalidation loss_recon: 0.013752484321594238\nvalidation DSC: 0.9787294268608093\n\nEpoch 19/30\n\ntrain loss: 0.01163475215435028\ntrain loss_segm: 0.01163475215435028\ntrain loss_shape: 0.40845781326293945\ntrain loss_recon: 0.013056553602218628\ntrain DSC: 0.9849221110343933\n\nvalidation loss: 0.01618882715702057\nvalidation loss_segm: 0.01618882715702057\nvalidation loss_shape: 0.7755804061889648\nvalidation loss_recon: 0.014685148000717163\nvalidation DSC: 0.9726383090019226\n\nEpoch 20/30\n\ntrain loss: 0.011107066869735718\ntrain loss_segm: 0.011107066869735718\ntrain loss_shape: 0.42977643966674806\ntrain loss_recon: 0.011976619958877563\ntrain DSC: 0.9846851825714111\n\nvalidation loss: 0.012666663527488709\nvalidation loss_segm: 0.012666663527488709\nvalidation loss_shape: 0.49512510299682616\nvalidation loss_recon: 0.014068067073822021\nvalidation DSC: 0.9814288020133972\n\nEpoch 21/30\n\ntrain loss: 0.009907556176185607\ntrain loss_segm: 0.009907556176185607\ntrain loss_shape: 0.34639530181884765\ntrain loss_recon: 0.011949588060379029\ntrain DSC: 0.9870942831039429\n\nvalidation loss: 0.013425561785697936\nvalidation loss_segm: 0.013425561785697936\nvalidation loss_shape: 0.6710681915283203\nvalidation loss_recon: 0.014618074893951416\nvalidation DSC: 0.977147102355957\n\nEpoch 22/30\n\ntrain loss: 0.00933063268661499\ntrain loss_segm: 0.00933063268661499\ntrain loss_shape: 0.3099159049987793\ntrain loss_recon: 0.011475321054458618\ntrain DSC: 0.9876055717468262\n\nvalidation loss: 0.013388201594352722\nvalidation loss_segm: 0.013388201594352722\nvalidation loss_shape: 0.7238623619079589\nvalidation loss_recon: 0.01437762975692749\nvalidation DSC: 0.9758264422416687\n\nEpoch 23/30\n\ntrain loss: 0.009469937682151795\ntrain loss_segm: 0.009469937682151795\ntrain loss_shape: 0.4298146438598633\ntrain loss_recon: 0.011509833335876464\ntrain DSC: 0.9858152866363525\n\nvalidation loss: 0.01254327893257141\nvalidation loss_segm: 0.01254327893257141\nvalidation loss_shape: 0.5782889366149903\nvalidation loss_recon: 0.014202237129211426\nvalidation DSC: 0.9775212407112122\n\nEpoch 24/30\n\ntrain loss: 0.009465583562850953\ntrain loss_segm: 0.009465583562850953\ntrain loss_shape: 0.4286278533935547\ntrain loss_recon: 0.011678733825683595\ntrain DSC: 0.9851694703102112\n\nvalidation loss: 0.012747818231582641\nvalidation loss_segm: 0.012747818231582641\nvalidation loss_shape: 0.4915890693664551\nvalidation loss_recon: 0.017069202661514283\nvalidation DSC: 0.97674560546875\n\nEpoch 25/30\n\ntrain loss: 0.010645545125007629\ntrain loss_segm: 0.010645545125007629\ntrain loss_shape: 0.5914502334594727\ntrain loss_recon: 0.013083324432373047\ntrain DSC: 0.9806880950927734\n\nvalidation loss: 0.014251965284347533\nvalidation loss_segm: 0.014251965284347533\nvalidation loss_shape: 0.6604521751403809\nvalidation loss_recon: 0.02036447525024414\nvalidation DSC: 0.9715032577514648\n\nEpoch 26/30\n\ntrain loss: 0.008708528280258178\ntrain loss_segm: 0.008708528280258178\ntrain loss_shape: 0.39477582931518557\ntrain loss_recon: 0.012215592861175538\ntrain DSC: 0.9853610396385193\n\nvalidation loss: 0.012317490577697755\nvalidation loss_segm: 0.012317490577697755\nvalidation loss_shape: 0.5613364219665528\nvalidation loss_recon: 0.017758142948150635\nvalidation DSC: 0.9765071868896484\n\nEpoch 27/30\n\ntrain loss: 0.007320947051048279\ntrain loss_segm: 0.007320947051048279\ntrain loss_shape: 0.28685855865478516\ntrain loss_recon: 0.010561861991882325\ntrain DSC: 0.9895185232162476\n\nvalidation loss: 0.011608991026878356\nvalidation loss_segm: 0.011608991026878356\nvalidation loss_shape: 0.5592921257019043\nvalidation loss_recon: 0.017060571908950807\nvalidation DSC: 0.9773882627487183\n\nEpoch 28/30\n\ntrain loss: 0.006890349388122559\ntrain loss_segm: 0.006890349388122559\ntrain loss_shape: 0.25011262893676756\ntrain loss_recon: 0.010388624668121339\ntrain DSC: 0.9901753067970276\n\nvalidation loss: 0.011032059788703918\nvalidation loss_segm: 0.011032059788703918\nvalidation loss_shape: 0.4057780265808105\nvalidation loss_recon: 0.015040117502212524\nvalidation DSC: 0.9784606695175171\n\nEpoch 29/30\n\ntrain loss: 0.006515361070632934\ntrain loss_segm: 0.006515361070632934\ntrain loss_shape: 0.2365018081665039\ntrain loss_recon: 0.010157957077026367\ntrain DSC: 0.9909762740135193\n\nvalidation loss: 0.010195973515510558\nvalidation loss_segm: 0.010195973515510558\nvalidation loss_shape: 0.39410247802734377\nvalidation loss_recon: 0.013340133428573608\nvalidation DSC: 0.9802486300468445\n\nEpoch 30/30\n\ntrain loss: 0.006369495391845703\ntrain loss_segm: 0.006369495391845703\ntrain loss_shape: 0.2638138961791992\ntrain loss_recon: 0.010341689586639405\ntrain DSC: 0.9909359812736511\n\nvalidation loss: 0.009707480669021606\nvalidation loss_segm: 0.009707480669021606\nvalidation loss_shape: 0.42376365661621096\nvalidation loss_recon: 0.013444644212722779\nvalidation DSC: 0.9813234210014343\nBest model saved after epoch 20 (val dsc = 0.9814288020133972).\n\ntest loss: 0.01070660636538551\ntest loss_segm: 0.01070660636538551\ntest loss_shape: 0.3658836001441592\ntest loss_recon: 0.012633545058114188\ntest DSC: 0.9842026233673096\nrm: cannot remove 'file.zip': No such file or directory\n  adding: ../results/Ellipsoids_FP_ellp_ed/ (stored 0%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/best_model.torch (deflated 8%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample0.nrrd (deflated 45%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample1.nrrd (deflated 47%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample10.nrrd (deflated 45%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample11.nrrd (deflated 48%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample12.nrrd (deflated 44%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample13.nrrd (deflated 46%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample14.nrrd (deflated 47%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample15.nrrd (deflated 48%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample16.nrrd (deflated 44%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample17.nrrd (deflated 44%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample18.nrrd (deflated 45%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample19.nrrd (deflated 46%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample2.nrrd (deflated 45%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample20.nrrd (deflated 46%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample3.nrrd (deflated 47%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample4.nrrd (deflated 44%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample5.nrrd (deflated 47%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample6.nrrd (deflated 47%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample7.nrrd (deflated 45%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample8.nrrd (deflated 46%)\n  adding: ../results/Ellipsoids_FP_ellp_ed/test_sample9.nrrd (deflated 44%)\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676996260807
        }
      },
      "id": "22747d54-19fe-4441-bd5e-adb5a4ee829b"
    },
    {
      "cell_type": "code",
      "source": [
        "# image = next(iter(dataloader['validation']))['t1'][tio.DATA].numpy()[0, 0]\n",
        "# for i in range(1, 64, 10):\n",
        "#     plt.imshow(image[i], cmap='gray')\n",
        "#     plt.show()"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676949040146
        }
      },
      "id": "5629af5b-6e5f-4e17-a405-94174f729ebf"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "58a2ca0e-7c99-4b67-ab2c-56a9fa705bf4"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": false,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}